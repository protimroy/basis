{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from tqdm import trange;\n",
    "import pandas as pd;\n",
    "from matplotlib import pyplot as plt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy__version: 1.26.4\n",
      "Pandas__version: 2.1.4\n"
     ]
    }
   ],
   "source": [
    "print( \"NumPy__version:\", np.__version__ );\n",
    "print( \"Pandas__version:\", pd.__version__ );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_data():\n",
    "    input_array = np.array( [ [ 0.0, 0.0 ], [ 0.0, 1.0 ], [ 1.0, 0.0 ], [ 1.0, 1.0 ] ] );\n",
    "    output_array = np.array( [ [ 0.0 ], [ 1.0 ], [ 1.0 ], [ 0.0 ] ] );\n",
    "    return ( input_array.astype('float32'), output_array.astype('float32') ),\\\n",
    "( input_array.astype('float32'), output_array.astype('float32') );\n",
    "\n",
    "def load_data( name ):\n",
    "    if name == \"xor\":\n",
    "        return xor_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print( type( load_data( \"xor\" )[0][0] ) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss( object ):\n",
    "    def __init__( self, name : str ):\n",
    "        self.name = name;\n",
    "\n",
    "    def __call__( self, y_pred, y_true, deriv=False ):\n",
    "        if self.name == \"mse\" and deriv==False:\n",
    "            return np.mean( ( y_pred - y_true ) ** 2 );\n",
    "    \n",
    "        elif self.name == \"cross_entropy\" and deriv==False:\n",
    "            return -np.mean( y_true * np.log( y_pred ) + ( 1 - y_true ) * np.log( 1 - y_pred ) );\n",
    "\n",
    "        elif self.name == \"cross_entropy\" and deriv==True:\n",
    "            # Clip predictions to avoid division by zero\n",
    "            y_pred = np.clip( y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "            # Compute the derivative of the binary cross-entropy loss\n",
    "            derivative = (y_pred - y_true) / (y_pred * (1 - y_pred));\n",
    "            return derivative\n",
    "        \n",
    "        else:\n",
    "            raise ValueError( \"Invalid loss function\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot( Y ):\n",
    "    \"\"\"\n",
    "    return an 0 vector with 1 only in the position correspondind to the value in Y\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros( ( Y.max()+1, Y.size ) ) ;\n",
    "    one_hot_Y[Y,np.arange( Y.size )] = 1; \n",
    "    return one_hot_Y;\n",
    "\n",
    "class BackProp( object ):\n",
    "    def __init__( self ) -> None:\n",
    "        pass;\n",
    "\n",
    "    def __call__( self, data : np.ndarray , labels : np.ndarray , size : int, logits : dict , trainable_variables : dict, transfer_function : callable ) -> dict:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # compute gradients\n",
    "        grads = {};\n",
    "    \n",
    "        loss_value = np.dot( 2 , logits['output'] - labels );\n",
    "        dw2 = np.dot( 1/size, loss_value.dot( logits['hidden'].T ) );\n",
    "        db2 = 1/size * np.sum( loss_value, 1 );\n",
    "\n",
    "        dz1 = trainable_variables['W_hidden_output_layer'].T.dot( loss_value ) * transfer_function( logits['W_input_hidden_layer'], deriv=True );\n",
    "\n",
    "        dw1 = 1/size * dz1.dot( data.T );\n",
    "        db1 = 1/size * np.sum( dz1, 1 );\n",
    "\n",
    "        grads['W_hidden_output_layer'] = dw2;\n",
    "        grads['output'] = db2;\n",
    "        grads['W_input_hidden_layer'] = dw1;\n",
    "        grads['hidden'] = db1;\n",
    "\n",
    "        error = np.sum( loss_value ** 2 ) / size;\n",
    "\n",
    "        return grads, error;\n",
    "\n",
    "class GradientDescent(object):\n",
    "    \"\"\"\n",
    "    Gradient Descent optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters: dict):\n",
    "        self.parameters = parameters;\n",
    "        self.name = \"Gradient Descent\";\n",
    "    \n",
    "    def minimize( self, trainable_variables, grads ):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for key in trainable_variables.keys():\n",
    "            if key[0] != 'W':\n",
    "                trainable_variables[key] -= self.parameters['lr'] * np.reshape( grads[key], ( self.parameters['hidden_units'],1) );\n",
    "            else:\n",
    "                x = self.parameters['lr'] * grads[key];\n",
    "                trainable_variables[key] -= x.T;\n",
    "\n",
    "        return trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer( object ):\n",
    "    \"\"\"\n",
    "    Base class for the Layer class.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name : str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Base Layer class.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            node_no : int\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.params : dict\n",
    "            self.node_no : int\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "\n",
    "        \"\"\"\n",
    "        self.hyperparams = hyperparams;\n",
    "        self.name = name;\n",
    "\n",
    "    def __rshift__( self, other ):\n",
    "        \"\"\"\n",
    "        Overwrite the right shift operator to connect the layers.\n",
    "\n",
    "        args:\n",
    "            other : object\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return NeuralNetwork( self, other );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputLayer( BaseLayer ):\n",
    "    \"\"\"\n",
    "    Input layer for the perceptron.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name: str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Input Layer class.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            node_no : int\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.bias : array\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super( InputLayer, self ).__init__( hyperparams, name );\n",
    "        self.node_no = hyperparams['input_units'];\n",
    "    \n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Mirror the inputs.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.bias_add = inputs;\n",
    "        self.activated = inputs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer( BaseLayer ):\n",
    "    \"\"\"\n",
    "    Layer class for the perceptron.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name: str, transfer: str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Layer class.\n",
    "\n",
    "        args:\n",
    "            name : str\n",
    "            params : dict\n",
    "            node_no : int\n",
    "            transfer : str\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.name : str\n",
    "            self.transfer : str\n",
    "            self.inputs : object\n",
    "            self.outputs : object\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super( Layer, self ).__init__( hyperparams, name );\n",
    "        self.transfer_name = transfer;\n",
    "\n",
    "        self.inputs = None;\n",
    "        self.outputs = None;\n",
    "    \n",
    "        if \"hidden\" in name:\n",
    "            self.node_no = hyperparams['hidden_units'];\n",
    "        else:\n",
    "            self.node_no = hyperparams['output_units'];\n",
    "        \n",
    "        #create self.bias to be an array of size node_no with random values from a normal distribution between -1 and 1\n",
    "        self.bias = np.random.rand( hyperparams['hidden_units'], hyperparams['examples'] ) - 0.5;\n",
    "        self.bias = self.bias.astype('float32');\n",
    "\n",
    "    def transfer_fx( self, inputs, deriv=False ):\n",
    "        \"\"\"\n",
    "        Transfer function for the layer.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if self.transfer_name == \"relu\" and deriv == True:\n",
    "            return inputs > 0;\n",
    "    \n",
    "        # implement the relu transfer function\n",
    "        if self.transfer_name == \"relu\" and deriv == False:\n",
    "            return np.maximum( 0,inputs );\n",
    "        \n",
    "        if self.transfer_name == 'softmax' and deriv == False:\n",
    "            exp = np.exp( inputs - np.max( inputs ) );\n",
    "            return exp / exp.sum( axis=0 );\n",
    "            \n",
    "        if self.transfer_name == \"sigmoid\" and deriv == True:\n",
    "            print( \"inputs:\",inputs );\n",
    "            print( \"1-inputs:\",1 - inputs );\n",
    "            f_x = 1 / ( 1 + np.exp( -inputs ) );\n",
    "            return f_x * ( 1 - f_x ); \n",
    "    \n",
    "        # implement the sigmoid transfer function\n",
    "        if self.transfer_name == \"sigmoid\" and deriv == False:\n",
    "            print( \"-inputs:\",-inputs );\n",
    "            print( \"np.exp( -inputs )\",np.exp( -inputs  ) );\n",
    "            return 1 / ( 1 + np.exp( -inputs ) );\n",
    "\n",
    "\n",
    "    def output( self, inputs, deriv=False ):\n",
    "        \"\"\"\n",
    "        Calculate the output with the activation function and inputs.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            self.outputs : array\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.bias_add = inputs + self.bias;\n",
    "        if deriv == True:\n",
    "            self.activated = self.transfer_fx( self.bias_add, deriv=True );\n",
    "        else:\n",
    "            self.activated = self.transfer_fx( self.bias_add );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightLayer( BaseLayer ):\n",
    "    \"\"\"\n",
    "    Weight layer for the perceptron.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__( self, src : Layer, dest : Layer ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the weight layer.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            src : Layer\n",
    "            dest : Layer\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.src : Layer\n",
    "            self.dest : Layer\n",
    "            self.input_size : tuple\n",
    "            self.output_size : tuple\n",
    "            self.name : str\n",
    "            self.weights : array\n",
    "\n",
    "        raises: \n",
    "            None\n",
    "        \"\"\"\n",
    "        self.src = src;\n",
    "        self.dest = dest;\n",
    "    \n",
    "        self.weights = np.random.rand( self.src.node_no, self.dest.bias.shape[0] ) - 0.5;\n",
    "        self.weights = self.weights.astype('float32');\n",
    "\n",
    "        self.name    = \"W_%s_%s_layer\" % ( self.src.name, self.dest.name );\n",
    "\n",
    "        self.src.outputs = self;\n",
    "        self.dest.inputs = self;\n",
    "\n",
    "\n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Matrix multiplication between the inputs and the weights.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.src.output( inputs );\n",
    "        return self.src.bias_add, self.src.activated, self.weights.T.dot( self.src.activated );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork( object ):\n",
    "    \"\"\"\n",
    "    This class respresents a Neural Networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__( self, layer0, layer1 ):\n",
    "        \"\"\"\n",
    "        Constructor for the Neural Network class.\n",
    "        Creates a network with an input layer, layer0 and an output layer, layer1.\n",
    "\n",
    "        args:\n",
    "            layer0 : object\n",
    "            layer1 : object\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.hyperparams          : ( dict ) hyperparameters for the network.\n",
    "            self.layers               : ( list ) list of layers in the network.\n",
    "            self.layer_name           : ( list ) list of names of the layers in the network.\n",
    "            self.input_layer          : ( object ) input layer of the network.\n",
    "            self.output_layer         : ( object ) output layer of the network.\n",
    "            self.weights              : ( list ) list of weights in the network.\n",
    "            self.weight_names         : ( list ) list of names of the weights in the network.\n",
    "            self.loss_fn              : ( object ) loss function for the network.\n",
    "            self.optimizer            : ( object ) optimizer for the network.\n",
    "            self.learnable_parameters : ( dict ) dictionary of learnable parameters in the network.\n",
    "\n",
    "        raises:\n",
    "            None \n",
    "        \"\"\"\n",
    "        # hyperparameters dictionary\n",
    "        self.hyperparams = layer0.hyperparams;\n",
    "\n",
    "        # layers\n",
    "        self.layers = [ layer0, layer1 ];\n",
    "        self.layer_name = [ layer0.name, layer1.name ];\n",
    "        self.input_layer = layer0;\n",
    "        self.output_layer = self.layers[-1];\n",
    "\n",
    "        # weights\n",
    "        self.weights = [ WeightLayer( layer0, layer1 ) ];\n",
    "        self.weight_names = [ self.weights[0].name ];\n",
    "\n",
    "        # loss function\n",
    "        self.loss_fn = None;\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = None;\n",
    "\n",
    "        # initialize and populate learnable parameters used for learning\n",
    "        self.trainable_parameters = {};\n",
    "        for weight in self.weights:\n",
    "            self.trainable_parameters[weight.name] = weight.weights;\n",
    "        for layer in self.layers[1:]:\n",
    "            self.trainable_parameters[layer.name] = layer.bias;\n",
    "\n",
    "    \n",
    "    def summary( self ):\n",
    "        \"\"\"\n",
    "        Print the summary of the network.\n",
    "\n",
    "        args:\n",
    "            None\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print( \"-------\" );\n",
    "        print( \"| Summary |\" );\n",
    "        print( \"-------\" );\n",
    "        print( f\"Input Layer: { self.input_layer.node_no }\" );\n",
    "        print( f\"Hidden Layer: { self.layers[1].node_no }\" );\n",
    "        print( f\"Output Layer: { self.output_layer.node_no }\" );\n",
    "    \n",
    "        print( \"-------\" );\n",
    "        print( \"| Weights |\" );\n",
    "        print( \"-------\" );\n",
    "        for weight_obj in self.weights:\n",
    "            print( f\"{weight_obj.name}: \\n {weight_obj.weights} , {weight_obj.weights.shape}\" );\n",
    "        \n",
    "        print( \"-------\" );\n",
    "        print( \"| Bias |\" );\n",
    "        print( \"------\" );\n",
    "        for layer_obj in self.layers:\n",
    "            if hasattr( layer_obj, 'bias' ):\n",
    "                print( f\"{layer_obj.name}: \\n {layer_obj.bias}, {layer_obj.bias.shape}\" );\n",
    "            else:\n",
    "                print( f\"{layer_obj.name}: \" );\n",
    "        \n",
    "        print( \"---------------\" );\n",
    "        print( \"| Hyperparameters |\" );\n",
    "        print( \"---------------\" );\n",
    "        print( f\"Epochs: {self.hyperparams['epochs']}\" );\n",
    "        print( f\"Learning Rate: {self.hyperparams['lr']}\" );\n",
    "        print( f\"Minibatch Size: {self.hyperparams['minibatch_size']}\" );\n",
    "        print( \"---------------\" );\n",
    "\n",
    "        print( \"---------------\" );\n",
    "        print( f\"| Loss Function | : {self.loss_fn.name}\" );\n",
    "        print( \"---------------\" );\n",
    "        \n",
    "        print( \"---------------\" );\n",
    "        #print( f\"| Optimizer | : {self.optimizer.name}\" );\n",
    "        print( \"---------------\" );\n",
    "\n",
    "        print( \"---------------\" );\n",
    "        print( \"| Trainable Parameters | \")\n",
    "        print( \"---------------\" );\n",
    "        print( self.trainable_parameters );\n",
    "    \n",
    "\n",
    "    def __rshift__( self, other ):\n",
    "        \"\"\"\n",
    "        Overwrite the right shift operator to add a layer to the network\n",
    "        \"\"\"\n",
    "        if isinstance( other, Layer ) or isinstance( other, InputLayer ):\n",
    "            # add weights between the layers, append the weight name to the list\n",
    "            self.weights.append( WeightLayer( self.layers[-1], other ) );\n",
    "            self.weight_names.append( self.weights[-1].name );\n",
    "            \n",
    "            # add the layer to the network, set the output layer to the last layer, and append the layer name to the list\n",
    "            self.layers.append( other );\n",
    "            self.output_layer = self.layers[-1];\n",
    "            self.layer_name.append( other.name );\n",
    "\n",
    "            # add the weights and biases to the trainable parameters\n",
    "            self.trainable_parameters[self.weights[-1].name] = self.weights[-1].weights;\n",
    "            self.trainable_parameters[other.name] = other.bias;\n",
    "\n",
    "            return self;\n",
    "    \n",
    "        if isinstance( other, Loss ):\n",
    "            self.loss_fn = other;\n",
    "            return self;\n",
    "\n",
    "        if isinstance( other, GradientDescent ):\n",
    "            self.optimizer = other;\n",
    "            return self;\n",
    "\n",
    "        else:\n",
    "            print( type( other ) );\n",
    "\n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Calculate the output of the network.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return self.output_layer.output( inputs );\n",
    "\n",
    "    def forward( self, inputs ):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        fwd_output = {};\n",
    "\n",
    "        for i in range( len( self.weights ) ):\n",
    "            src_bias_add, src_activated, inputs = self.weights[i].output( inputs );\n",
    "            \n",
    "            fwd_output[self.weights[i].name] = inputs;\n",
    "            if self.layers[i].name == 'input':\n",
    "                continue;\n",
    "            fwd_output[self.layers[i].name] = src_activated;\n",
    "            fwd_output[self.layers[i].name + \"_bias_add\"] = src_bias_add;\n",
    "        \n",
    "        self.output( inputs );\n",
    "        fwd_output['output'] = self.output_layer.activated;\n",
    "        fwd_output['output_bias_add'] = self.output_layer.bias_add;\n",
    "        \n",
    "        return fwd_output;\n",
    "\n",
    "    def predict( self, X ):\n",
    "        \"\"\"\n",
    "        Predict the output of the network.\n",
    "\n",
    "        args:\n",
    "            X : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        logits = self.forward( X );\n",
    "        return np.argmax( logits['output'], 0 );\n",
    "\n",
    "    def get_accuracy( self, predictions, Y ):\n",
    "        return np.sum( predictions == Y )/Y.size\n",
    "\n",
    "    def train( self, X, y ):\n",
    "        \"\"\"\n",
    "        Train the network.\n",
    "\n",
    "        args:\n",
    "            X : array\n",
    "            y : array\n",
    "            epochs : int\n",
    "            lr : float\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        self.losses_pd = pd.DataFrame( columns = ['fwd_losses'], index=[0] );\n",
    "        self.weights_pd = pd.DataFrame();\n",
    "        self.bias_pd = pd.DataFrame();\n",
    "        self.weight_layer_output_pd = pd.DataFrame();\n",
    "        self.activated_pd  = pd.DataFrame();\n",
    "        self.grad_pd = pd.DataFrame();\n",
    "\n",
    "        for i in range( len( self.weights ) ):\n",
    "            weights = self.weights[i];\n",
    "            for l in range ( weights.weights.shape[0] ):\n",
    "                for j in range( weights.weights.shape[1] ):\n",
    "                    self.weights_pd.loc[ 0 ,  weights.name + f\"{l}_{j}\" ] = weights.weights[l][j];\n",
    "        \n",
    "        for i in range( len( self.layers ) ):\n",
    "            layer = self.layers[i];\n",
    "            if hasattr( layer, 'bias' ):\n",
    "                for j in range( layer.bias.shape[0] ):\n",
    "                    self.bias_pd.loc[ 0, layer.name + f\"{j}\" ] = layer.bias[j];\n",
    "        \n",
    "        \n",
    "        #print( self.weights_pd )\n",
    "        #print( self.bias_pd )\n",
    "        \"\"\"\n",
    "\n",
    "        for epoch in range( self.hyperparams['epochs'] ):\n",
    "  \n",
    "            # forward pass\n",
    "            #z1, a1, z2, a2 = self.forward( X );\n",
    "            fwd_outputs = self.forward( X );\n",
    "\n",
    "            #for item in fwd_outputs:\n",
    "                #print( item, fwd_outputs[item].shape );\n",
    "\n",
    "            # logging\n",
    "            #for name in self.weight_names:\n",
    "                #for i in range( fwd_outputs[name].shape[0] ):\n",
    "                    #for j in range( fwd_outputs[name].shape[1] ):\n",
    "                        #self.weight_layer_output_pd.loc[ 0, name + f\"{i}_{j}\" ] = fwd_outputs[name][i][j];\n",
    "                \n",
    "            #for name in self.layer_name[1:]:\n",
    "                #for i in range( fwd_outputs[name].shape[0] ):\n",
    "                    #for j in range( fwd_outputs[name].shape[1] ):\n",
    "                       # self.activated_pd.loc[ 0, name + f\"{i}_{j}\" ] = fwd_outputs[name][i][j];\n",
    "        \n",
    "\n",
    "            # backward pass\n",
    "            #one_hot_labels = one_hot( y )\n",
    "            size = y.size;\n",
    "            \n",
    "            grads, error = BackProp()( X, y, size, fwd_outputs, self.trainable_parameters, self.layers[1].transfer_fx );\n",
    "            \n",
    "            # update the weights\n",
    "            self.trainable_parameters = self.optimizer.minimize( self.trainable_parameters, grads );\n",
    "\n",
    "            # update the weights and biases\n",
    "            for weight in self.weights:\n",
    "                weight.weights = self.trainable_parameters[weight.name];\n",
    "\n",
    "            for layer in self.layers[1:]:\n",
    "                layer.bias = self.trainable_parameters[layer.name];\n",
    "\n",
    "            print( f\"Epoch: {epoch+1} / {self.hyperparams['epochs']}, Error: {error}\" );\n",
    "            #if ( epoch+1 ) % int( self.hyperparams['epochs']/10 ) == 0:\n",
    "                #print(f\"Iteration: {epoch+1} / {self.hyperparams['epochs']}\")\n",
    "                #prediction = self.predict( X );\n",
    "                #print(f'{self.get_accuracy(prediction, y):.3%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = load_data( \"xor\" );\n",
    "x_train, y_train = training[0].T, training[1].T;\n",
    "x_test, y_test = testing[0].T, testing[1].T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    #seed\n",
    "    \"seed\" : 42,\n",
    "\n",
    "    \"examples\" : x_train.shape[1],\n",
    "    \n",
    "    # model hyperparameters\n",
    "    \"input_units\" : x_train.shape[0],\n",
    "    \"hidden_units\" : 2,\n",
    "    \"output_units\" : 1,\n",
    "\n",
    "    # optimizer hyperparameters\n",
    "    \"lr\" : 0.15,\n",
    "\n",
    "    # training hyperparameters\n",
    "    \"epochs\" : 100,\n",
    "    \"minibatch_size\" : 4\n",
    "}\n",
    "#np.random.seed(params['seed']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = InputLayer( params, \"input\" );\n",
    "hidden_layer = Layer( params, \"hidden\", \"sigmoid\" );\n",
    "output_layer = Layer( params, \"output\", \"sigmoid\" );\n",
    "\n",
    "loss = Loss( \"cross_entropy\" );\n",
    "optimizer = GradientDescent( params );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = input_layer >> hidden_layer >> output_layer >> loss >> optimizer;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inputs: [[ 0.3794611   0.18691097 -0.05070847 -0.7901538 ]\n",
      " [ 0.24823572 -0.02858008  0.65091646  0.3117391 ]]\n",
      "np.exp( -inputs ) [[1.4614968  1.20552    0.9505558  0.45377502]\n",
      " [1.281762   0.9718244  1.9172971  1.3657982 ]]\n",
      "-inputs: [[ 0.41937587 -0.21674185  0.4157359   0.05131501]\n",
      " [ 0.46019453 -0.41183862  0.00872019 -0.28185147]]\n",
      "np.exp( -inputs ) [[1.521012   0.8051378  1.5154856  1.0526545 ]\n",
      " [1.5843822  0.66243124 1.0087583  0.75438565]]\n",
      "inputs: [[ 0.         -0.06299692  0.40641746  0.34342054]\n",
      " [ 0.         -0.04600008 -0.39606413 -0.44206423]]\n",
      "1-inputs: [[1.        1.0629969 0.5935825 0.6565795]\n",
      " [1.        1.0460001 1.3960642 1.4420643]]\n",
      "Epoch: 1 / 100, Error: 1.8421691681172918\n",
      "-inputs: [[ 0.37952033  0.18595143 -0.05036932 -0.7908334 ]\n",
      " [ 0.24565826 -0.0274782   0.64614284  0.3106448 ]]\n",
      "np.exp( -inputs ) [[1.4615831  1.2043638  0.9508782  0.4534667 ]\n",
      " [1.2784626  0.97289586 1.9081665  1.3643045 ]]\n",
      "-inputs: [[ 0.4048269  -0.2315818   0.401436    0.03653459]\n",
      " [ 0.46884766 -0.4022888   0.01787043 -0.2707393 ]]\n",
      "np.exp( -inputs ) [[1.4990429  0.79327774 1.4939684  1.0372101 ]\n",
      " [1.5981514  0.6687876  1.018031   0.76281536]]\n",
      "inputs: [[ 0.         -0.06197818  0.40613753  0.34415936]\n",
      " [ 0.         -0.04967943 -0.39386797 -0.4435474 ]]\n",
      "1-inputs: [[1.         1.0619782  0.5938625  0.65584064]\n",
      " [1.         1.0496794  1.393868   1.4435474 ]]\n",
      "Epoch: 2 / 100, Error: 1.8406354124034605\n",
      "-inputs: [[ 0.3795801   0.18504825 -0.05004504 -0.7914721 ]\n",
      " [ 0.24330002 -0.02580347  0.64185     0.31038493]]\n",
      "np.exp( -inputs ) [[1.4616708  1.2032765  0.9511866  0.45317718]\n",
      " [1.2754512  0.9745266  1.8999925  1.36395   ]]\n",
      "-inputs: [[ 0.39176664 -0.24487013  0.38863894  0.02339542]\n",
      " [ 0.47653207 -0.39373273  0.02605629 -0.26066452]]\n",
      "np.exp( -inputs ) [[1.4795924  0.78280616 1.4749719  1.0236713 ]\n",
      " [1.6104796  0.6745343  1.0263988  0.77053934]]\n",
      "inputs: [[ 0.         -0.06101523  0.40587303  0.3448578 ]\n",
      " [ 0.         -0.05371239 -0.39193335 -0.44564575]]\n",
      "1-inputs: [[1.         1.0610152  0.59412694 0.6551422 ]\n",
      " [1.         1.0537124  1.3919333  1.4456458 ]]\n",
      "Epoch: 3 / 100, Error: 1.839351141650278\n",
      "-inputs: [[ 0.37963998  0.18418989 -0.04973376 -0.79207903]\n",
      " [ 0.24114719 -0.02358872  0.6380149   0.31091744]]\n",
      "np.exp( -inputs ) [[1.4617581 1.202244  0.9514828 0.4529022]\n",
      " [1.2727083 0.9766874 1.8927199 1.3646766]]\n",
      "-inputs: [[ 0.38003948 -0.25676805  0.37718832  0.01172757]\n",
      " [ 0.48334587 -0.38606888  0.03337593 -0.2515208 ]]\n",
      "np.exp( -inputs ) [[1.4623424 0.7735476 1.4581789 1.0117966]\n",
      " [1.6214905 0.6797237 1.0339391 0.7776173]]\n",
      "inputs: [[ 0.         -0.06009699  0.40562162  0.34552464]\n",
      " [ 0.         -0.05807997 -0.39025113 -0.4483311 ]]\n",
      "1-inputs: [[1.         1.060097   0.59437835 0.65447533]\n",
      " [1.         1.05808    1.3902512  1.4483311 ]]\n",
      "Epoch: 4 / 100, Error: 1.8382650319564675\n",
      "-inputs: [[ 0.3796996   0.18336609 -0.04943377 -0.79266244]\n",
      " [ 0.23918808 -0.0208612   0.634619    0.31220818]]\n",
      "np.exp( -inputs ) [[1.4618453  1.2012541  0.95176816 0.45263806]\n",
      " [1.2702174  0.97935486 1.8863033  1.3664392 ]]\n",
      "-inputs: [[ 0.3695055  -0.26742077  0.3669434   0.00137784]\n",
      " [ 0.4893772  -0.37920555  0.03991787 -0.24321206]]\n",
      "np.exp( -inputs ) [[1.4470189  0.76535094 1.4433161  1.0013788 ]\n",
      " [1.6312999  0.68440497 1.0407254  0.7841052 ]]\n",
      "inputs: [[ 0.         -0.05921357  0.40538123  0.34616765]\n",
      " [ 0.         -0.06276661 -0.38881433 -0.45158094]]\n",
      "1-inputs: [[1.        1.0592135 0.5946188 0.6538323]\n",
      " [1.        1.0627666 1.3888143 1.451581 ]]\n",
      "Epoch: 5 / 100, Error: 1.8373357193993627\n",
      "-inputs: [[ 0.37975863  0.18256776 -0.04914361 -0.79322964]\n",
      " [ 0.23741283 -0.0176433   0.63164735  0.31422973]]\n",
      "np.exp( -inputs ) [[1.4619317 1.2002954 0.9520444 0.4523814]\n",
      " [1.2679646 0.9825114 1.8807061 1.3692043]]\n",
      "-inputs: [[ 0.3600389  -0.27695897  0.3577775  -0.00779159]\n",
      " [ 0.49470565 -0.37305993  0.04576175 -0.23565134]]\n",
      "np.exp( -inputs ) [[1.4333851  0.7580856  1.4301473  0.99223864]\n",
      " [1.6400155  0.68862396 1.0468249  0.79005605]]\n",
      "inputs: [[ 0.         -0.05835621  0.40515012  0.3467939 ]\n",
      " [ 0.         -0.06775977 -0.38761795 -0.45537773]]\n",
      "1-inputs: [[1.        1.0583562 0.5948499 0.6532061]\n",
      " [1.        1.0677598 1.387618  1.4553777]]\n",
      "Epoch: 6 / 100, Error: 1.83653037330126\n",
      "-inputs: [[ 0.37981686  0.18178692 -0.04886201 -0.7937871 ]\n",
      " [ 0.23581326 -0.01395302  0.62908864  0.31696078]]\n",
      "np.exp( -inputs ) [[1.4620167  1.1993586  0.95231247 0.45212927]\n",
      " [1.2659378  0.9861439  1.8759001  1.3729488 ]]\n",
      "-inputs: [[ 0.35152674 -0.28550005  0.34957704 -0.01590463]\n",
      " [ 0.4994026  -0.3675574   0.0509795  -0.22876036]]\n",
      "np.exp( -inputs ) [[1.4212357  0.75163823 1.4184674  0.9842212 ]\n",
      " [1.6477367  0.6924235  1.0523014  0.7955192 ]]\n",
      "inputs: [[ 0.         -0.05751714  0.40492675  0.3474096 ]\n",
      " [ 0.         -0.07304961 -0.38665876 -0.45970836]]\n",
      "1-inputs: [[1.        1.0575172 0.5950732 0.6525904]\n",
      " [1.        1.0730497 1.3866588 1.4597083]]\n",
      "Epoch: 7 / 100, Error: 1.8358230034083398\n",
      "-inputs: [[ 0.3798741   0.1810165  -0.0485878  -0.7943406 ]\n",
      " [ 0.23438269 -0.0098045   0.62693447  0.32038575]]\n",
      "np.exp( -inputs ) [[1.4621004 1.198435  0.9525737 0.4518791]\n",
      " [1.2641282 0.9902434 1.8718636 1.3776591]]\n",
      "-inputs: [[ 0.3438676  -0.29314947  0.3422399  -0.0230725 ]\n",
      " [ 0.50353235 -0.3626308   0.05563555 -0.2224684 ]]\n",
      "np.exp( -inputs ) [[1.4103919 0.7459106 1.4080981 0.9771917]\n",
      " [1.6545554 0.6958433 1.0572124 0.8005403]]\n",
      "inputs: [[ 0.         -0.05668947  0.4047098   0.34802032]\n",
      " [ 0.         -0.07862871 -0.3859352  -0.4645639 ]]\n",
      "1-inputs: [[1.        1.0566895 0.5952902 0.6519797]\n",
      " [1.        1.0786287 1.3859352 1.4645638]]\n",
      "Epoch: 8 / 100, Error: 1.8351923862115997\n",
      "-inputs: [[ 0.3799303   0.18025029 -0.04831991 -0.79489505]\n",
      " [ 0.23311575 -0.00520827  0.6251795   0.32449394]]\n",
      "np.exp( -inputs ) [[1.4621826  1.197517   0.95282894 0.45162863]\n",
      " [1.2625277  0.99480534 1.8685814  1.3833305 ]]\n",
      "-inputs: [[ 0.33697075 -0.30000162  0.3356746  -0.02939498]\n",
      " [ 0.5071526  -0.35821953  0.05978812 -0.21671173]]\n",
      "np.exp( -inputs ) [[1.4006982  0.740817   1.3988837  0.97103286]\n",
      " [1.6605562  0.69891965 1.0616117  0.80516195]]\n",
      "inputs: [[ 0.         -0.0558671   0.40449807  0.34863096]\n",
      " [ 0.         -0.08449188 -0.38544717 -0.46993905]]\n",
      "1-inputs: [[1.         1.0558671  0.5955019  0.65136904]\n",
      " [1.         1.0844918  1.3854471  1.469939  ]]\n",
      "Epoch: 9 / 100, Error: 1.8346219583273582\n",
      "-inputs: [[ 3.7998533e-01  1.7948286e-01 -4.8057348e-02 -7.9545498e-01]\n",
      " [ 2.3200834e-01 -1.7160922e-04  6.2382102e-01  3.2927951e-01]]\n",
      "np.exp( -inputs ) [[1.4622631  1.1965984  0.95307916 0.4513758 ]\n",
      " [1.2611302  0.9998284  1.8660446  1.3899662 ]]\n",
      "-inputs: [[ 0.3307548  -0.30614126  0.32979926 -0.03496148]\n",
      " [ 0.510315   -0.35426924  0.06348935 -0.21143314]]\n",
      "np.exp( -inputs ) [[1.3920184  0.7362826  1.3906889  0.96564263]\n",
      " [1.6658158  0.701686   1.0655482  0.8094234 ]]\n",
      "inputs: [[ 0.         -0.05504463  0.40429056  0.34924594]\n",
      " [ 0.         -0.09063596 -0.38519606 -0.47583202]]\n",
      "1-inputs: [[1.         1.0550447  0.59570944 0.6507541 ]\n",
      " [1.         1.090636   1.3851961  1.475832  ]]\n",
      "Epoch: 10 / 100, Error: 1.8340984784605654\n",
      "-inputs: [[ 0.38003922  0.17870943 -0.04779926 -0.7960242 ]\n",
      " [ 0.23105745  0.00530124  0.6228585   0.33474082]]\n",
      "np.exp( -inputs ) [[1.4623419  1.1956733  0.95332515 0.45111898]\n",
      " [1.2599316  1.0053153  1.8642493  1.3975781 ]]\n",
      "-inputs: [[ 0.32514682 -0.31164414  0.32454044 -0.03985205]\n",
      " [ 0.51306605 -0.3507309   0.06678621 -0.20658076]]\n",
      "np.exp( -inputs ) [[1.3842338  0.73224205 1.3833948  0.9609316 ]\n",
      " [1.6704049  0.70417327 1.0690669  0.8133606 ]]\n",
      "inputs: [[ 0.         -0.05421731  0.40408635  0.34986904]\n",
      " [ 0.         -0.09705968 -0.3851845  -0.4822442 ]]\n",
      "1-inputs: [[1.         1.0542173  0.59591365 0.650131  ]\n",
      " [1.         1.0970597  1.3851845  1.4822443 ]]\n",
      "Epoch: 11 / 100, Error: 1.8336115735916305\n",
      "-inputs: [[ 0.380092    0.17792585 -0.04754481 -0.7966061 ]\n",
      " [ 0.23026118  0.01120888  0.6222943   0.34088042]]\n",
      "np.exp( -inputs ) [[1.462419  1.1947367 0.9535678 0.4508565]\n",
      " [1.2589287 1.011272  1.8631979 1.406185 ]]\n",
      "-inputs: [[ 0.32008168 -0.3165781   0.31983244 -0.04413835]\n",
      " [ 0.51544726 -0.34756047  0.06972089 -0.20210826]]\n",
      "np.exp( -inputs ) [[1.3772403  0.72863805 1.3768971  0.9568216 ]\n",
      " [1.6743872  0.7064093  1.0722089  0.81700647]]\n",
      "inputs: [[ 0.         -0.05338094  0.40388468  0.35050374]\n",
      " [ 0.         -0.1037636  -0.3854165  -0.4891801 ]]\n",
      "1-inputs: [[1.         1.053381   0.59611535 0.64949626]\n",
      " [1.         1.1037636  1.3854165  1.4891801 ]]\n",
      "Epoch: 12 / 100, Error: 1.8331527361994597\n",
      "-inputs: [[ 0.38014376  0.17712852 -0.04729316 -0.79720354]\n",
      " [ 0.2296186   0.01755263  0.62213254  0.347705  ]]\n",
      "np.exp( -inputs ) [[1.4624947  1.1937845  0.9538077  0.45058724]\n",
      " [1.2581201  1.0177076  1.8628966  1.4158145 ]]\n",
      "-inputs: [[ 0.315501   -0.32100382  0.31561652 -0.04788451]\n",
      " [ 0.517496   -0.3447184   0.07233109 -0.19797376]]\n",
      "np.exp( -inputs ) [[1.370946   0.7254204  1.3711044  0.95324385]\n",
      " [1.677821   0.7084198  1.0750113  0.82039136]]\n",
      "inputs: [[ 0.         -0.05253185  0.4036848   0.35115296]\n",
      " [ 0.         -0.11074994 -0.3858973  -0.49664724]]\n",
      "1-inputs: [[1.         1.0525318  0.5963152  0.64884704]\n",
      " [1.         1.11075    1.3858973  1.4966472 ]]\n",
      "Epoch: 13 / 100, Error: 1.8327156247942646\n",
      "-inputs: [[ 0.3801946   0.1763143  -0.04704365 -0.79781914]\n",
      " [ 0.22912972  0.02433646  0.6223798   0.35522497]]\n",
      "np.exp( -inputs ) [[1.4625691  1.1928129  0.9540457  0.45030996]\n",
      " [1.2575052  1.0246351  1.8633572  1.4265014 ]]\n",
      "-inputs: [[ 0.31135267 -0.3249755   0.31184012 -0.05114776]\n",
      " [ 0.5192456  -0.3421691   0.07465094 -0.19413942]]\n",
      "np.exp( -inputs ) [[1.3652706  0.722545   1.3659363  0.9501383 ]\n",
      " [1.6807592  0.710228   1.0775081  0.82354313]]\n",
      "inputs: [[ 0.         -0.0516668   0.40348613  0.35181934]\n",
      " [ 0.         -0.11802264 -0.38663343 -0.5046561 ]]\n",
      "1-inputs: [[1.         1.0516669  0.59651387 0.64818066]\n",
      " [1.         1.1180227  1.3866334  1.5046561 ]]\n",
      "Epoch: 14 / 100, Error: 1.8322950832847749\n",
      "-inputs: [[ 0.38024467  0.17548051 -0.04679558 -0.7984549 ]\n",
      " [ 0.22879551  0.03156687  0.6230447   0.36345452]]\n",
      "np.exp( -inputs ) [[1.4626424  1.1918187  0.95428246 0.45002374]\n",
      " [1.257085   1.0320704  1.8645966  1.4382894 ]]\n",
      "-inputs: [[ 0.30759004 -0.3285416   0.30845624 -0.05397936]\n",
      " [ 0.520726   -0.33988065  0.07671092 -0.19057128]]\n",
      "np.exp( -inputs ) [[1.3601432  0.7199729  1.3613219  0.94745165]\n",
      " [1.6832491  0.71185523 1.0797298  0.8264868 ]]\n",
      "inputs: [[ 0.         -0.05078297  0.40328813  0.35250515]\n",
      " [ 0.         -0.12558724 -0.38763258 -0.51321983]]\n",
      "1-inputs: [[1.         1.0507829  0.5967119  0.64749485]\n",
      " [1.         1.1255872  1.3876326  1.5132198 ]]\n",
      "Epoch: 15 / 100, Error: 1.8318869792587806\n",
      "-inputs: [[ 0.3802941   0.17462489 -0.04654831 -0.7991127 ]\n",
      " [ 0.22861786  0.03925288  0.62413824  0.37241173]]\n",
      "np.exp( -inputs ) [[1.4627146  1.1907994  0.95451844 0.44972786]\n",
      " [1.2568617  1.0400335  1.8666368  1.4512304 ]]\n",
      "-inputs: [[ 0.30417135 -0.3317454   0.3054229  -0.05642501]\n",
      " [ 0.52196395 -0.33782423  0.07853841 -0.18723875]]\n",
      "np.exp( -inputs ) [[1.3555013 0.71767   1.3571988 0.9451374]\n",
      " [1.6853343 0.7133206 1.081705  0.8292457]]\n",
      "inputs: [[ 0.         -0.0498779   0.4030903   0.35321242]\n",
      " [ 0.         -0.13345091 -0.3889038  -0.5223547 ]]\n",
      "1-inputs: [[1.        1.0498779 0.5969097 0.6467876]\n",
      " [1.        1.1334509 1.3889039 1.5223547]]\n",
      "Epoch: 16 / 100, Error: 1.8314881562711287\n",
      "-inputs: [[ 0.38034317  0.17374548 -0.04630119 -0.79979396]\n",
      " [ 0.22859955  0.04740612  0.6256736   0.38211858]]\n",
      "np.exp( -inputs ) [[1.4627864  1.1897527  0.9547544  0.44942153]\n",
      " [1.2568387  1.0485477  1.8695047  1.4653858 ]]\n",
      "-inputs: [[ 0.3010594  -0.33462554  0.30270252 -0.05852555]\n",
      " [ 0.5229832  -0.33597404  0.08015808 -0.18411425]]\n",
      "np.exp( -inputs ) [[1.3512896 0.7156059 1.3535118 0.9431541]\n",
      " [1.687053  0.7146416 1.0834583 0.8318408]]\n",
      "inputs: [[ 0.         -0.04894944  0.40289223  0.35394278]\n",
      " [ 0.         -0.14162247 -0.39045742 -0.5320799 ]]\n",
      "1-inputs: [[1.         1.0489495  0.59710777 0.64605725]\n",
      " [1.         1.1416224  1.3904574  1.5320799 ]]\n",
      "Epoch: 17 / 100, Error: 1.8310958898276448\n",
      "-inputs: [[ 0.38039204  0.17284068 -0.04605365 -0.80050015]\n",
      " [ 0.22874425  0.05604076  0.627666    0.39260095]]\n",
      "np.exp( -inputs ) [[1.462858   1.1886767  0.9549907  0.44910428]\n",
      " [1.2570206  1.0576409  1.8732333  1.4808273 ]]\n",
      "-inputs: [[ 0.29822084 -0.33721644  0.30026165 -0.0603174 ]\n",
      " [ 0.5238052  -0.33430675  0.08159202 -0.18117273]]\n",
      "np.exp( -inputs ) [[1.3474593  0.71375436 1.350212   0.9414656 ]\n",
      " [1.6884402  0.7158341  1.0850132  0.8342912 ]]\n",
      "inputs: [[ 0.         -0.04799576  0.40269357  0.3546978 ]\n",
      " [ 0.         -0.1501124  -0.39230514 -0.5424175 ]]\n",
      "1-inputs: [[1.         1.0479958  0.59730643 0.6453022 ]\n",
      " [1.         1.1501124  1.3923051  1.5424175 ]]\n",
      "Epoch: 18 / 100, Error: 1.8307086194814897\n",
      "-inputs: [[ 0.38044098  0.17190914 -0.04580513 -0.8012321 ]\n",
      " [ 0.22905663  0.06517365  0.6301333   0.4038888 ]]\n",
      "np.exp( -inputs ) [[1.4629295  1.1875699  0.95522803 0.44877568]\n",
      " [1.2574133  1.0673443  1.8778608  1.4976374 ]]\n",
      "-inputs: [[ 0.29562595 -0.33954892  0.29807034 -0.06183304]\n",
      " [ 0.52444905 -0.33280128  0.0828602  -0.17839164]]\n",
      "np.exp( -inputs ) [[1.3439674  0.71209145 1.3472565  0.9400398 ]\n",
      " [1.6895278  0.71691257 1.0863899  0.8366147 ]]\n",
      "inputs: [[ 0.         -0.04701528  0.40249398  0.3554787 ]\n",
      " [ 0.         -0.15893292 -0.39446005 -0.553393  ]]\n",
      "1-inputs: [[1.         1.0470153  0.59750605 0.6445213 ]\n",
      " [1.         1.1589329  1.3944601  1.553393  ]]\n",
      "Epoch: 19 / 100, Error: 1.830324388220494\n",
      "-inputs: [[ 0.38049024  0.17094977 -0.04555508 -0.8019907 ]\n",
      " [ 0.22954227  0.07482443  0.6330956   0.41601628]]\n",
      "np.exp( -inputs ) [[1.4630016  1.1864312  0.9554669  0.44843537]\n",
      " [1.2580241  1.0776949  1.8834319  1.5159105 ]]\n",
      "-inputs: [[ 0.29324824 -0.3416503   0.29610187 -0.06310142]\n",
      " [ 0.5249318  -0.33143878  0.0839805  -0.17575052]]\n",
      "np.exp( -inputs ) [[1.3407755  0.7105966  1.3446071  0.93884826]\n",
      " [1.6903436  0.7178901  1.0876077  0.8388272 ]]\n",
      "inputs: [[ 0.         -0.04600665  0.4022932   0.35628656]\n",
      " [ 0.         -0.16809806 -0.39693677 -0.56503487]]\n",
      "1-inputs: [[1.        1.0460067 0.5977068 0.6437135]\n",
      " [1.        1.1680981 1.3969368 1.5650349]]\n",
      "Epoch: 20 / 100, Error: 1.8299423983349792\n",
      "-inputs: [[ 0.38054013  0.16996174 -0.04530296 -0.80277646]\n",
      " [ 0.2302078   0.08501565  0.63657594  0.42902225]]\n",
      "np.exp( -inputs ) [[1.4630746  1.1852595  0.95570797 0.44808313]\n",
      " [1.2588615  1.0887341  1.8899983  1.5357552 ]]\n",
      "-inputs: [[ 0.29106385 -0.34354505  0.2943324  -0.06414835]\n",
      " [ 0.52526855 -0.33020213  0.08496904 -0.17323086]]\n",
      "np.exp( -inputs ) [[1.33785    0.7092515  1.3422301  0.93786585]\n",
      " [1.6909128  0.7187784  1.0886834  0.84094346]]\n",
      "inputs: [[ 0.         -0.04496871  0.40209097  0.35712224]\n",
      " [ 0.         -0.17762375 -0.3997515  -0.5773753 ]]\n",
      "1-inputs: [[1.         1.0449687  0.59790903 0.64287776]\n",
      " [1.         1.1776237  1.3997515  1.5773753 ]]\n",
      "Epoch: 21 / 100, Error: 1.8295615236875378\n",
      "-inputs: [[ 0.38059095  0.16894437 -0.04504827 -0.80359   ]\n",
      " [ 0.23106094  0.09577298  0.6405998   0.44295025]]\n",
      "np.exp( -inputs ) [[1.463149  1.1840543 0.9559514 0.4477188]\n",
      " [1.259936  1.1005092 1.8976188 1.557295 ]]\n",
      "-inputs: [[ 0.28905165 -0.34525493  0.2927407  -0.06499681]\n",
      " [ 0.52547306 -0.32907587  0.08584049 -0.17081577]]\n",
      "np.exp( -inputs ) [[1.3351607  0.70803976 1.3400953  0.9370705 ]\n",
      " [1.6912587  0.7195884  1.0896325  0.84297687]]\n",
      "inputs: [[ 0.         -0.04390053  0.4018871   0.35798657]\n",
      " [ 0.         -0.18752794 -0.40292224 -0.59045017]]\n",
      "1-inputs: [[1.         1.0439005  0.59811294 0.64201343]\n",
      " [1.         1.1875279  1.4029223  1.5904502 ]]\n",
      "Epoch: 22 / 100, Error: 1.8291812738152249\n",
      "-inputs: [[ 0.380643    0.16789722 -0.04479054 -0.80443144]\n",
      " [ 0.23211052  0.10712541  0.6451959   0.4578492 ]]\n",
      "np.exp( -inputs ) [[1.463225   1.1828151  0.95619774 0.4473422 ]\n",
      " [1.2612591  1.1130738  1.9063605  1.5806706 ]]\n",
      "-inputs: [[ 0.28719276 -0.34679925  0.29130778 -0.06566719]\n",
      " [ 0.52555734 -0.32804585  0.08660792 -0.16848978]]\n",
      "np.exp( -inputs ) [[1.3326811  0.70694727 1.3381764  0.93644255]\n",
      " [1.6914012  0.72032994 1.090469   0.8449399 ]]\n",
      "inputs: [[ 0.         -0.04280133  0.40168142  0.3588801 ]\n",
      " [ 0.         -0.19783078 -0.40646878 -0.60429955]]\n",
      "1-inputs: [[1.        1.0428014 0.5983186 0.6411199]\n",
      " [1.        1.1978308 1.4064687 1.6042995]]\n",
      "Epoch: 23 / 100, Error: 1.828800831303366\n",
      "-inputs: [[ 0.38069665  0.16681999 -0.04452926 -0.8053011 ]\n",
      " [ 0.23336665  0.11910553  0.6503962   0.47377354]]\n",
      "np.exp( -inputs ) [[1.4633036  1.1815414  0.9564476  0.44695333]\n",
      " [1.2628444  1.1264888  1.9162999  1.6060433 ]]\n",
      "-inputs: [[ 0.28547022 -0.34819525  0.29001674 -0.06617767]\n",
      " [ 0.5255321  -0.32709926  0.08728327 -0.16623881]]\n",
      "np.exp( -inputs ) [[1.3303875 0.705961  1.3364499 0.9359646]\n",
      " [1.6913587 0.7210121 1.0912057 0.846844 ]]\n",
      "inputs: [[ 0.         -0.04167046  0.4014738   0.35980332]\n",
      " [ 0.         -0.20855476 -0.41041297 -0.6189677 ]]\n",
      "1-inputs: [[1.         1.0416704  0.59852624 0.6401967 ]\n",
      " [1.         1.2085547  1.410413   1.6189678 ]]\n",
      "Epoch: 24 / 100, Error: 1.8284202221225145\n",
      "-inputs: [[ 0.3807522   0.1657125  -0.04426402 -0.80619884]\n",
      " [ 0.2348408   0.13174984  0.65623635  0.49078387]]\n",
      "np.exp( -inputs ) [[1.4633849  1.1802337  0.9567013  0.44655222]\n",
      " [1.2647074  1.1408229  1.9275241  1.6335962 ]]\n",
      "-inputs: [[ 0.283869   -0.3494582   0.28885254 -0.06654439]\n",
      " [ 0.5254071  -0.32622457  0.08787744 -0.16404998]]\n",
      "np.exp( -inputs ) [[1.3282589  0.70507    1.3348949  0.93562144]\n",
      " [1.6911471  0.7216431  1.0918543  0.8486996 ]]\n",
      "inputs: [[ 0.         -0.04050742  0.4012641   0.36075667]\n",
      " [ 0.         -0.21972494 -0.41477895 -0.6345039 ]]\n",
      "1-inputs: [[1.         1.0405074  0.5987359  0.63924336]\n",
      " [1.         1.2197249  1.414779   1.6345038 ]]\n",
      "Epoch: 25 / 100, Error: 1.8280389560888715\n",
      "-inputs: [[ 0.38081005  0.16457477 -0.04399431 -0.80712473]\n",
      " [ 0.23654588  0.14509918  0.6627557   0.5089475 ]]\n",
      "np.exp( -inputs ) [[1.4634696  1.1788917  0.95695937 0.44613898]\n",
      " [1.2668656  1.1561543  1.9401314  1.6635394 ]]\n",
      "-inputs: [[ 0.28237563 -0.35060164  0.28780177 -0.06678162]\n",
      " [ 0.5251907  -0.32541078  0.08840016 -0.16191125]]\n",
      "np.exp( -inputs ) [[1.3262768  0.7042642  1.333493   0.9353994 ]\n",
      " [1.6907811  0.72223055 1.0924251  0.8505167 ]]\n",
      "inputs: [[ 0.         -0.03931185  0.40105224  0.36174038]\n",
      " [ 0.         -0.23136918 -0.41959327 -0.6509625 ]]\n",
      "1-inputs: [[1.         1.0393119  0.59894776 0.63825965]\n",
      " [1.         1.2313691  1.4195933  1.6509625 ]]\n",
      "Epoch: 26 / 100, Error: 1.8276567059066782\n",
      "-inputs: [[ 0.38087052  0.16340688 -0.04371974 -0.8080785 ]\n",
      " [ 0.23849648  0.15919909  0.66999835  0.5283394 ]]\n",
      "np.exp( -inputs ) [[1.4635582  1.1775157  0.95722216 0.44571367]\n",
      " [1.2693392  1.1725714  1.954234   1.6961135 ]]\n",
      "-inputs: [[ 0.28097817 -0.35163754  0.28685254 -0.06690201]\n",
      " [ 0.52489066 -0.3246482   0.08886059 -0.15981156]]\n",
      "np.exp( -inputs ) [[1.3244246  0.7035351  1.3322278  0.9352868 ]\n",
      " [1.690274   0.72278154 1.0929283  0.8523044 ]]\n",
      "inputs: [[ 0.         -0.03808347  0.40083814  0.36275467]\n",
      " [ 0.         -0.24351847 -0.42488527 -0.66840374]]\n",
      "1-inputs: [[1.         1.0380834  0.59916186 0.6372453 ]\n",
      " [1.         1.2435185  1.4248853  1.6684037 ]]\n",
      "Epoch: 27 / 100, Error: 1.8272736664035145\n",
      "-inputs: [[ 0.38093403  0.162209   -0.04343987 -0.80906   ]\n",
      " [ 0.240709    0.17410031  0.6780129   0.5490426 ]]\n",
      "np.exp( -inputs ) [[1.4636511  1.176106   0.9574901  0.44527644]\n",
      " [1.2721508  1.1901749  1.9699594  1.7315942 ]]\n",
      "-inputs: [[ 0.27966592 -0.3525766   0.28599432 -0.06691679]\n",
      " [ 0.52451384 -0.32392746  0.08926702 -0.15774053]]\n",
      "np.exp( -inputs ) [[1.3226879  0.7028748  1.3310848  0.93527305]\n",
      " [1.6896372  0.7233027  1.0933726  0.8540713 ]]\n",
      "inputs: [[ 0.         -0.03682211  0.40062177  0.36379966]\n",
      " [ 0.         -0.25620717 -0.43068728 -0.6868944 ]]\n",
      "1-inputs: [[1.        1.0368221 0.5993782 0.6362003]\n",
      " [1.        1.2562072 1.4306873 1.6868944]]\n",
      "Epoch: 28 / 100, Error: 1.826889615766274\n",
      "-inputs: [[ 0.38100094  0.16098148 -0.04315427 -0.81006885]\n",
      " [ 0.24320188  0.18985954  0.6868535   0.5711496 ]]\n",
      "np.exp( -inputs ) [[1.4637489  1.1746632  0.9577636  0.44482747]\n",
      " [1.275326   1.2090797  1.9874524  1.770301  ]]\n",
      "-inputs: [[ 0.2784294  -0.35342813  0.28521767 -0.06683576]\n",
      " [ 0.5240662  -0.32324     0.08962707 -0.1556885 ]]\n",
      "np.exp( -inputs ) [[1.3210534  0.70227647 1.3300515  0.93534875]\n",
      " [1.688881   0.72380006 1.0937663  0.8558257 ]]\n",
      "inputs: [[ 0.         -0.03552767  0.40040308  0.3648754 ]\n",
      " [ 0.         -0.26947352 -0.43703505 -0.7065086 ]]\n",
      "1-inputs: [[1.         1.0355277  0.5995969  0.63512456]\n",
      " [1.         1.2694736  1.4370351  1.7065086 ]]\n",
      "Epoch: 29 / 100, Error: 1.8265047658939375\n",
      "-inputs: [[ 0.38107166  0.15972468 -0.0428625  -0.8111046 ]\n",
      " [ 0.24599582  0.20653996  0.69658065  0.59476316]]\n",
      "np.exp( -inputs ) [[1.4638524  1.1731879  0.95804316 0.44436696]\n",
      " [1.2788942  1.2294168  2.0068789  1.8126016 ]]\n",
      "-inputs: [[ 0.2772601  -0.3542003   0.28451437 -0.06666765]\n",
      " [ 0.52355325 -0.32257766  0.08994797 -0.15364629]]\n",
      "np.exp( -inputs ) [[1.3195095  0.7017344  1.3291163  0.93550605]\n",
      " [1.6880149  0.72427964 1.0941174  0.8575753 ]]\n",
      "inputs: [[ 0.         -0.03420016  0.40018204  0.36598188]\n",
      " [ 0.         -0.28336    -0.44396818 -0.7273282 ]]\n",
      "1-inputs: [[1.        1.0342002 0.599818  0.6340181]\n",
      " [1.        1.28336   1.4439682 1.7273282]]\n",
      "Epoch: 30 / 100, Error: 1.8261191528043206\n",
      "-inputs: [[ 0.38114658  0.15843906 -0.04256421 -0.8121668 ]\n",
      " [ 0.24911411  0.22421212  0.7072613   0.6199977 ]]\n",
      "np.exp( -inputs ) [[1.4639621  1.1716806  0.95832884 0.4438952 ]\n",
      " [1.2828884  1.2513366  2.0284286  1.8589237 ]]\n",
      "-inputs: [[ 0.27615058 -0.35490027  0.2838771  -0.06642006]\n",
      " [ 0.52297974 -0.32193255  0.09023647 -0.15160516]]\n",
      "np.exp( -inputs ) [[1.3180463  0.70124334 1.3282696  0.9357378 ]\n",
      " [1.6870471  0.724747   1.0944331  0.8593275 ]]\n",
      "inputs: [[ 0.         -0.03283961  0.39995867  0.36711904]\n",
      " [ 0.         -0.29791388 -0.45153055 -0.7494444 ]]\n",
      "1-inputs: [[1.         1.0328397  0.60004133 0.6328809 ]\n",
      " [1.         1.2979139  1.4515306  1.7494445 ]]\n",
      "Epoch: 31 / 100, Error: 1.8257329113876875\n",
      "-inputs: [[ 0.38122612  0.15712515 -0.04225895 -0.8132551 ]\n",
      " [ 0.25258297  0.24295494  0.71897054  0.6469809 ]]\n",
      "np.exp( -inputs ) [[1.4640787  1.170142   0.95862144 0.44341236]\n",
      " [1.2873462  1.2750112  2.0523193  1.9097663 ]]\n",
      "-inputs: [[ 0.2750942  -0.35553434  0.28329942 -0.06609961]\n",
      " [ 0.52235013 -0.32129726  0.09049888 -0.14955673]]\n",
      "np.exp( -inputs ) [[1.3166547  0.7007989  1.3275025  0.93603754]\n",
      " [1.6859853  0.7252076  1.0947204  0.8610896 ]]\n",
      "inputs: [[ 0.         -0.03144616  0.39973295  0.3682868 ]\n",
      " [ 0.         -0.31318784 -0.45977092 -0.77295876]]\n",
      "1-inputs: [[1.         1.0314462  0.60026705 0.6317132 ]\n",
      " [1.         1.3131878  1.4597709  1.7729588 ]]\n",
      "Epoch: 32 / 100, Error: 1.8253466147656647\n",
      "-inputs: [[ 0.3813107   0.15578353 -0.04194632 -0.8143686 ]\n",
      " [ 0.25643194  0.26285684  0.73179215  0.6758554 ]]\n",
      "np.exp( -inputs ) [[1.4642024  1.1685733  0.9589212  0.44291893]\n",
      " [1.2923108  1.3006406  2.0788028  1.9657137 ]]\n",
      "-inputs: [[ 0.27408522 -0.35610783  0.2827757  -0.0657121 ]\n",
      " [ 0.52166843 -0.32066426  0.09074146 -0.147493  ]]\n",
      "np.exp( -inputs ) [[1.3153269 0.7003971 1.3268075 0.9364004]\n",
      " [1.6848363 0.7256669 1.094986  0.8628685]]\n",
      "inputs: [[ 0.         -0.03001997  0.3995049   0.36948493]\n",
      " [ 0.         -0.32924074 -0.46874356 -0.7979843 ]]\n",
      "1-inputs: [[1.        1.03002   0.6004951 0.6305151]\n",
      " [1.        1.3292408 1.4687436 1.7979844]]\n",
      "Epoch: 33 / 100, Error: 1.8249597999563614\n",
      "-inputs: [[ 0.38140073  0.15441486 -0.04162598 -0.815507  ]\n",
      " [ 0.26069438  0.28401694  0.7458201   0.706781  ]]\n",
      "np.exp( -inputs ) [[1.4643341  1.1669749  0.95922846 0.442415  ]\n",
      " [1.297831   1.3284554  2.1081696  2.0274544 ]]\n",
      "-inputs: [[ 0.27311847 -0.35662535  0.2823012  -0.06526249]\n",
      " [ 0.5209383  -0.32002622  0.09097008 -0.14540619]]\n",
      "np.exp( -inputs ) [[1.3140559  0.70003474 1.3261781  0.9368215 ]\n",
      " [1.6836066  0.72612995 1.0952362  0.864671  ]]\n",
      "inputs: [[ 0.         -0.02856125  0.3992746   0.37071335]\n",
      " [ 0.         -0.3461384  -0.47850907 -0.8246474 ]]\n",
      "1-inputs: [[1.         1.0285612  0.6007254  0.62928665]\n",
      " [1.         1.3461384  1.4785091  1.8246474 ]]\n",
      "Epoch: 34 / 100, Error: 1.8245739700105545\n",
      "-inputs: [[ 0.38149667  0.15301979 -0.04129747 -0.81666946]\n",
      " [ 0.26540804  0.3065468   0.76116     0.7399372 ]]\n",
      "np.exp( -inputs ) [[1.4644748 1.165348  0.9595437 0.441901 ]\n",
      " [1.303963  1.3587252 2.140758  2.095804 ]]\n",
      "-inputs: [[ 0.27218953 -0.35709062  0.2818716  -0.06475509]\n",
      " [ 0.52016306 -0.3193758   0.09119065 -0.14328876]]\n",
      "np.exp( -inputs ) [[1.3128358  0.6997091  1.3256085  0.9372969 ]\n",
      " [1.682302   0.7266024  1.0954778  0.86650383]]\n",
      "inputs: [[ 0.         -0.02707024  0.399042    0.37197176]\n",
      " [ 0.         -0.3639546  -0.4891353  -0.8530899 ]]\n",
      "1-inputs: [[1.        1.0270703 0.600958  0.6280283]\n",
      " [1.        1.3639545 1.4891353 1.8530899]]\n",
      "Epoch: 35 / 100, Error: 1.82418872318806\n",
      "-inputs: [[ 0.38159892  0.15159905 -0.04096043 -0.8178555 ]\n",
      " [ 0.2706157   0.33057222  0.77793074  0.7755257 ]]\n",
      "np.exp( -inputs ) [[1.4646245  1.1636937  0.9598671  0.44137716]\n",
      " [1.3107712  1.3917643  2.1769629  2.1717334 ]]\n",
      "-inputs: [[ 0.27129465 -0.3575069   0.28148335 -0.06419355]\n",
      " [ 0.5193461  -0.31870547  0.09140909 -0.14113331]]\n",
      "np.exp( -inputs ) [[1.3116615  0.6994179  1.3250939  0.9378234 ]\n",
      " [1.6809281  0.72708964 1.0957172  0.8683735 ]]\n",
      "inputs: [[ 0.         -0.02554723  0.39880723  0.37326   ]\n",
      " [ 0.         -0.38277236 -0.5006984  -0.8834708 ]]\n",
      "1-inputs: [[1.        1.0255473 0.6011928 0.62674  ]\n",
      " [1.        1.3827723 1.5006983 1.8834708]]\n",
      "Epoch: 36 / 100, Error: 1.823805276917711\n",
      "-inputs: [[ 0.38170794  0.15015337 -0.04061449 -0.8190642 ]\n",
      " [ 0.27636603  0.35623538  0.7962668   0.8137746 ]]\n",
      "np.exp( -inputs ) [[1.4647841  1.1620123  0.96019924 0.44084403]\n",
      " [1.3183304  1.4279436  2.2172482  2.256409  ]]\n",
      "-inputs: [[ 0.27043068 -0.35787657  0.28113353 -0.06358102]\n",
      " [ 0.51849055 -0.3180073   0.09163134 -0.1389327 ]]\n",
      "np.exp( -inputs ) [[1.3105289  0.6991594  1.3246305  0.93839806]\n",
      " [1.6794906  0.7275974  1.0959607  0.8702866 ]]\n",
      "inputs: [[ 0.         -0.02399253  0.3985703   0.37457776]\n",
      " [ 0.         -0.4026852  -0.51328415 -0.9159694 ]]\n",
      "1-inputs: [[1.         1.0239925  0.6014297  0.62542224]\n",
      " [1.         1.4026852  1.5132842  1.9159694 ]]\n",
      "Epoch: 37 / 100, Error: 1.8234244235431065\n",
      "-inputs: [[ 0.38182417  0.14868353 -0.04025924 -0.82029504]\n",
      " [ 0.28271452  0.38369766  0.81632066  0.8549422 ]]\n",
      "np.exp( -inputs ) [[1.4649544  1.1603057  0.9605404  0.44030175]\n",
      " [1.3267263  1.4677016  2.2621613  2.3512383 ]]\n",
      "-inputs: [[ 0.26959503 -0.35820156  0.2808197  -0.06292009]\n",
      " [ 0.51759976 -0.31727326  0.09186341 -0.13667995]]\n",
      "np.exp( -inputs ) [[1.309434   0.69893223 1.3242148  0.9390185 ]\n",
      " [1.6779953  0.7281317  1.0962151  0.8722493 ]]\n",
      "inputs: [[ 0.         -0.02240645  0.39833128  0.37592483]\n",
      " [ 0.         -0.42379898 -0.5269895  -0.9507885 ]]\n",
      "1-inputs: [[1.        1.0224065 0.6016687 0.6240752]\n",
      " [1.        1.423799  1.5269895 1.9507885]]\n",
      "Epoch: 38 / 100, Error: 1.8230472399776598\n",
      "-inputs: [[ 0.38194805  0.1471903  -0.03989428 -0.8215472 ]\n",
      " [ 0.28972474  0.41314277  0.8382659   0.8993223 ]]\n",
      "np.exp( -inputs ) [[1.4651359  1.1585745  0.96089095 0.43975073]\n",
      " [1.3360597  1.5115607  2.3123536  2.4579368 ]]\n",
      "-inputs: [[ 0.26878566 -0.35848308  0.28053993 -0.062213  ]\n",
      " [ 0.51667684 -0.3164947   0.09211168 -0.13436839]]\n",
      "np.exp( -inputs ) [[1.3083746  0.6987355  1.3238444  0.9396827 ]\n",
      " [1.6764474  0.7286989  1.0964873  0.87426794]]\n",
      "inputs: [[ 0.         -0.02078931  0.3980902   0.3773009 ]\n",
      " [ 0.         -0.44623387 -0.5419245  -0.98815835]]\n",
      "1-inputs: [[1.         1.0207893  0.60190976 0.62269914]\n",
      " [1.         1.4462339  1.5419245  1.9881583 ]]\n",
      "Epoch: 39 / 100, Error: 1.8226749917176344\n",
      "-inputs: [[ 0.38208008  0.14567447 -0.03951922 -0.82282   ]\n",
      " [ 0.29746965  0.4447806   0.86230063  0.94725   ]]\n",
      "np.exp( -inputs ) [[1.4653294 1.1568196 0.9612515 0.4391914]\n",
      " [1.3464476 1.5601479 2.3686037 2.5786088]]\n",
      "-inputs: [[ 0.26800126 -0.3587218   0.28029275 -0.06146164]\n",
      " [ 0.51572555 -0.3156622   0.09238271 -0.1319918 ]]\n",
      "np.exp( -inputs ) [[1.3073488  0.69856864 1.3235172  0.940389  ]\n",
      " [1.6748532  0.72930574 1.0967846  0.8763482 ]]\n",
      "inputs: [[ 0.         -0.01914146  0.39784718  0.3787057 ]\n",
      " [ 0.         -0.47012678 -0.55821437 -1.0283412 ]]\n",
      "1-inputs: [[1.         1.0191414  0.6021528  0.62129426]\n",
      " [1.         1.4701267  1.5582144  2.0283413 ]]\n",
      "Epoch: 40 / 100, Error: 1.8223093084252913\n",
      "-inputs: [[ 0.38222066  0.14413679 -0.03913373 -0.8241128 ]\n",
      " [ 0.30603343  0.47885194  0.88865256  0.99910945]]\n",
      "np.exp( -inputs ) [[1.4655354 1.155042  0.9616221 0.438624 ]\n",
      " [1.3580276 1.61422   2.4318507 2.7158623]]\n",
      "-inputs: [[ 0.267241   -0.35891786  0.2800773  -0.06066769]\n",
      " [ 0.5147499  -0.31476593  0.09268376 -0.1295444 ]]\n",
      "np.exp( -inputs ) [[1.3063551  0.69843173 1.323232   0.94113594]\n",
      " [1.67322    0.72995967 1.0971147  0.8784956 ]]\n",
      "inputs: [[ 0.         -0.0174632   0.39760226  0.38013905]\n",
      " [ 0.         -0.49563435 -0.5760025  -1.0716368 ]]\n",
      "1-inputs: [[1.         1.0174632  0.60239774 0.61986095]\n",
      " [1.         1.4956343  1.5760025  2.0716367 ]]\n",
      "Epoch: 41 / 100, Error: 1.8219524716785198\n",
      "-inputs: [[ 0.38237026  0.14257805 -0.03873736 -0.8254248 ]\n",
      " [ 0.31551364  0.5156344   0.9175838   1.0553429 ]]\n",
      "np.exp( -inputs ) [[1.4657546  1.1532432  0.96200335 0.43804887]\n",
      " [1.3709633  1.6747006  2.5032349  2.8729599 ]]\n",
      "-inputs: [[ 0.26650482 -0.3590708   0.279893   -0.05983262]\n",
      " [ 0.51375437 -0.31379494  0.09302223 -0.12702107]]\n",
      "np.exp( -inputs ) [[1.3053938  0.6983249  1.3229883  0.9419221 ]\n",
      " [1.6715549  0.73066884 1.0974861  0.8807151 ]]\n",
      "inputs: [[ 0.         -0.01575485  0.3973555   0.38160065]\n",
      " [ 0.         -0.52293664 -0.5954535  -1.1183901 ]]\n",
      "1-inputs: [[1.        1.0157548 0.6026445 0.6183994]\n",
      " [1.        1.5229366 1.5954535 2.11839  ]]\n",
      "Epoch: 42 / 100, Error: 1.8216067561764726\n",
      "-inputs: [[ 0.38252938  0.140999   -0.03832972 -0.8267553 ]\n",
      " [ 0.32602376  0.55544955  0.9493982   1.1164623 ]]\n",
      "np.exp( -inputs ) [[1.4659879 1.1514235 0.9623956 0.4374664]\n",
      " [1.3854483 1.7427242 2.5841544 3.0540311]]\n",
      "-inputs: [[ 0.2657933  -0.35917974  0.2797398  -0.05895799]\n",
      " [ 0.51274437 -0.3127374   0.09340629 -0.12441772]]\n",
      "np.exp( -inputs ) [[1.3044654 0.6982488 1.3227855 0.9427464]\n",
      " [1.6698676 0.7314419 1.0979077 0.8830109]]\n",
      "inputs: [[ 0.         -0.01401668  0.39710698  0.3830903 ]\n",
      " [ 0.         -0.5522416  -0.6167578  -1.1689994 ]]\n",
      "1-inputs: [[1.         1.0140166  0.602893   0.61690974]\n",
      " [1.         1.5522416  1.6167579  2.1689994 ]]\n",
      "Epoch: 43 / 100, Error: 1.8212753196725\n",
      "-inputs: [[ 0.38269848  0.13940036 -0.0379104  -0.8281038 ]\n",
      " [ 0.3376967   0.5986717   0.98444974  1.1830631 ]]\n",
      "np.exp( -inputs ) [[1.4662358 1.1495843 0.9627992 0.4368769]\n",
      " [1.4017153 1.8197    2.6763387 3.264358 ]]\n",
      "-inputs: [[ 0.26510784 -0.35924315  0.279618   -0.05804552]\n",
      " [ 0.5117264  -0.31158048  0.09384474 -0.12173197]]\n",
      "np.exp( -inputs ) [[1.3035716  0.6982046  1.3226246  0.94360703]\n",
      " [1.6681685  0.73228866 1.0983891  0.8853857 ]]\n",
      "inputs: [[ 0.         -0.01224892  0.39685676  0.38460785]\n",
      " [ 0.         -0.58379084 -0.6401364  -1.2239273 ]]\n",
      "1-inputs: [[1.         1.0122489  0.6031432  0.61539215]\n",
      " [1.         1.5837908  1.6401365  2.2239273 ]]\n",
      "Epoch: 44 / 100, Error: 1.8209619871157425\n",
      "-inputs: [[ 0.38287804  0.13778275 -0.03747901 -0.82946956]\n",
      " [ 0.3506888   0.6457393   1.0231531   1.255842  ]]\n",
      "np.exp( -inputs ) [[1.4664991  1.1477262  0.9632146  0.43628064]\n",
      " [1.4200454  1.9073967  2.7819526  3.5107932 ]]\n",
      "-inputs: [[ 0.26445067 -0.35925922  0.27952814 -0.05709726]\n",
      " [ 0.51070803 -0.31031018  0.09434691 -0.11896327]]\n",
      "np.exp( -inputs ) [[1.3027152  0.6981934  1.3225057  0.94450223]\n",
      " [1.6664708  0.73321944 1.0989408  0.88784045]]\n",
      "inputs: [[ 0.         -0.01045173  0.39660493  0.3861532 ]\n",
      " [ 0.         -0.61786634 -0.6658476  -1.2837139 ]]\n",
      "1-inputs: [[1.        1.0104518 0.6033951 0.6138468]\n",
      " [1.        1.6178663 1.6658475 2.2837138]]\n",
      "Epoch: 45 / 100, Error: 1.8206714266937682\n",
      "-inputs: [[ 0.38306856  0.13614678 -0.03703511 -0.83085215]\n",
      " [ 0.36518523  0.6971691   1.065997    1.3356193 ]]\n",
      "np.exp( -inputs ) [[1.4667785  1.1458502  0.96364236 0.43567786]\n",
      " [1.4407808  2.0080602  2.9037323  3.80235   ]]\n",
      "-inputs: [[ 0.26382512 -0.35922575  0.2794712  -0.05611581]\n",
      " [ 0.50969887 -0.3089115   0.09492296 -0.11611372]]\n",
      "np.exp( -inputs ) [[1.3019005  0.6982168  1.3224304  0.9454297 ]\n",
      " [1.6647897  0.7342458  1.0995741  0.89037395]]\n",
      "inputs: [[ 0.         -0.00862523  0.39635155  0.3877263 ]\n",
      " [ 0.         -0.6547997  -0.69419515 -1.3489949 ]]\n",
      "1-inputs: [[1.        1.0086253 0.6036484 0.6122737]\n",
      " [1.        1.6547997 1.6941952 2.3489947]]\n",
      "Epoch: 46 / 100, Error: 1.820409073209012\n",
      "-inputs: [[ 0.38327056  0.13449293 -0.03657827 -0.8322511 ]\n",
      " [ 0.38140687  0.7535744   1.1135623   1.4233682 ]]\n",
      "np.exp( -inputs ) [[1.4670749  1.1439565  0.96408266 0.43506882]\n",
      " [1.4643433  2.1245804  3.0451868  4.1510787 ]]\n",
      "-inputs: [[ 0.2632355  -0.35914022  0.27944815 -0.05510473]\n",
      " [ 0.50871056 -0.3073681   0.09558351 -0.11318919]]\n",
      "np.exp( -inputs ) [[1.3011332  0.69827646 1.3223999  0.94638604]\n",
      " [1.6631453  0.7353798  1.1003008  0.89298165]]\n",
      "inputs: [[ 0.         -0.00676941  0.3960967   0.3893273 ]\n",
      " [ 0.         -0.6949833  -0.7255388  -1.4205221 ]]\n",
      "1-inputs: [[1.        1.0067694 0.6039033 0.6106727]\n",
      " [1.        1.6949832 1.7255387 2.4205222]]\n",
      "Epoch: 47 / 100, Error: 1.8201812447294445\n",
      "-inputs: [[ 0.38348454  0.13282163 -0.03610805 -0.83366615]\n",
      " [ 0.399619    0.8156883   1.1665435   1.5202512 ]]\n",
      "np.exp( -inputs ) [[1.4673887  1.1420463  0.96453613 0.4344536 ]\n",
      " [1.4912565  2.2607312  3.210875   4.573374  ]]\n",
      "-inputs: [[ 0.26268753 -0.35900036  0.27946007 -0.05406883]\n",
      " [ 0.5077575  -0.30566326  0.09633976 -0.11020043]]\n",
      "np.exp( -inputs ) [[1.3004204  0.69837415 1.3224156  0.94736683]\n",
      " [1.6615609  0.7366346  1.1011331  0.8956546 ]]\n",
      "inputs: [[ 0.         -0.00488415  0.39584047  0.3909563 ]\n",
      " [ 0.         -0.7388851  -0.7603078  -1.499193  ]]\n",
      "1-inputs: [[1.         1.0048841  0.60415953 0.6090437 ]\n",
      " [1.         1.7388852  1.7603078  2.499193  ]]\n",
      "Epoch: 48 / 100, Error: 1.819995860789934\n",
      "-inputs: [[ 0.383711    0.13113314 -0.03562403 -0.8350971 ]\n",
      " [ 0.42014304  0.88439506  1.2257783   1.6276687 ]]\n",
      "np.exp( -inputs ) [[1.4677212  1.1401196  0.965003   0.43383235]\n",
      " [1.5221791  2.421519   3.4068165  5.0919905 ]]\n",
      "-inputs: [[ 0.26218814 -0.35880405  0.2795078  -0.05301458]\n",
      " [ 0.5068574  -0.30377966  0.09720287 -0.10716429]]\n",
      "np.exp( -inputs ) [[1.2997711  0.69851124 1.3224788  0.94836617]\n",
      " [1.660066   0.73802346 1.1020839  0.8983781 ]]\n",
      "inputs: [[ 0.         -0.00296916  0.3955829   0.39261374]\n",
      " [ 0.         -0.78706783 -0.7990187  -1.5860865 ]]\n",
      "1-inputs: [[1.         1.0029691  0.6044171  0.60738623]\n",
      " [1.         1.7870679  1.7990186  2.5860865 ]]\n",
      "Epoch: 49 / 100, Error: 1.8198616780711605\n",
      "-inputs: [[ 0.38395056  0.12942752 -0.03512567 -0.8365439 ]\n",
      " [ 0.44337174  0.9607702   1.2922872   1.7473241 ]]\n",
      "np.exp( -inputs ) [[1.4680728  1.1381767  0.9654841  0.43320513]\n",
      " [1.5579512  2.6137087  3.6411052  5.739224  ]]\n",
      "-inputs: [[ 0.26174575 -0.35855013  0.27959135 -0.05195059]\n",
      " [ 0.50603217 -0.30170086  0.09818348 -0.10410568]]\n",
      "np.exp( -inputs ) [[1.2991962  0.69868857 1.3225893  0.9493758 ]\n",
      " [1.6586968  0.73955923 1.1031651  0.9011301 ]]\n",
      "inputs: [[ 0.0000000e+00 -1.0239986e-03  3.9532411e-01  3.9430010e-01]\n",
      " [ 0.0000000e+00 -8.4021425e-01 -8.4229887e-01 -1.6825131e+00]]\n",
      "1-inputs: [[1.        1.001024  0.6046759 0.6056999]\n",
      " [1.        1.8402143 1.8422989 2.6825132]]\n",
      "Epoch: 50 / 100, Error: 1.8197882456670245\n",
      "-inputs: [[ 0.38420376  0.12770468 -0.03461251 -0.8380068 ]\n",
      " [ 0.46979007  1.0461353   1.3673246   1.8813082 ]]\n",
      "np.exp( -inputs ) [[1.4684447  1.1362175  0.96597964 0.43257186]\n",
      " [1.5996583  2.8466282  3.924836   6.5620837 ]]\n",
      "-inputs: [[ 0.26137033 -0.358239    0.27970988 -0.05088814]\n",
      " [ 0.5053091  -0.299412    0.09929113 -0.10105893]]\n",
      "np.exp( -inputs ) [[1.2987086  0.698906   1.3227459  0.950385  ]\n",
      " [1.6574979  0.7412539  1.1043878  0.90387976]]\n",
      "inputs: [[ 0.0000000e+00  9.5203286e-04  3.9506415e-01  3.9601618e-01]\n",
      " [ 0.0000000e+00 -8.9916104e-01 -8.9091790e-01 -1.7900789e+00]]\n",
      "1-inputs: [[1.        0.999048  0.6049359 0.6039838]\n",
      " [1.        1.8991611 1.8909179 2.7900789]]\n",
      "Epoch: 51 / 100, Error: 1.8197862909043865\n",
      "-inputs: [[ 0.3844712   0.12596427 -0.03408402 -0.8394862 ]\n",
      " [ 0.50000334  1.1421328   1.4524505   2.0322182 ]]\n",
      "np.exp( -inputs ) [[1.4688374  1.1342416  0.96649027 0.4319324 ]\n",
      " [1.6487268  3.133444   4.2735744  7.6309953 ]]\n",
      "-inputs: [[ 0.26107323 -0.35787338  0.27986062 -0.0498414 ]\n",
      " [ 0.50472134 -0.2969025   0.10053214 -0.09807044]]\n",
      "np.exp( -inputs ) [[1.2983228  0.69916165 1.3229454  0.9513803 ]\n",
      " [1.6565237  0.7431164  1.1057591  0.90658504]]\n",
      "inputs: [[ 0.          0.00295989  0.3948031   0.397763  ]\n",
      " [ 0.         -0.9649452  -0.94583046 -1.9107757 ]]\n",
      "1-inputs: [[1.        0.9970401 0.6051969 0.602237 ]\n",
      " [1.        1.9649452 1.9458305 2.9107757]]\n",
      "Epoch: 52 / 100, Error: 1.8198659615344903\n",
      "-inputs: [[ 0.38475358  0.12420566 -0.03353962 -0.84098274]\n",
      " [ 0.53477633  1.2508278   1.5496283   2.203318  ]]\n",
      "np.exp( -inputs ) [[1.4692522  1.1322486  0.9670165  0.43128645]\n",
      " [1.7070663  3.4932334  4.7097187  9.05501   ]]\n",
      "-inputs: [[ 0.26086664 -0.35745996  0.28003806 -0.0488279 ]\n",
      " [ 0.50430936 -0.29416886  0.10190815 -0.09519982]]\n",
      "np.exp( -inputs ) [[1.2980547  0.69945073 1.3231802  0.9523451 ]\n",
      " [1.6558414  0.7451507  1.1072818  0.90919125]]\n",
      "inputs: [[ 0.          0.00500086  0.39454108  0.39954194]\n",
      " [ 0.         -1.0388674  -1.0082353  -2.0471027 ]]\n",
      "1-inputs: [[1.        0.9949991 0.6054589 0.600458 ]\n",
      " [1.        2.0388675 2.0082355 3.0471027]]\n",
      "Epoch: 53 / 100, Error: 1.820035970675904\n",
      "-inputs: [[ 0.38505158  0.12242791 -0.03297874 -0.8424976 ]\n",
      " [ 0.5750884   1.3748536   1.6613634   2.398767  ]]\n",
      "np.exp( -inputs ) [[ 1.4696901   1.1302377   0.9675591   0.43063363]\n",
      " [ 1.7772875   3.9544978   5.266486   11.009593  ]]\n",
      "-inputs: [[ 0.260763   -0.35701063  0.28023285 -0.04786812]\n",
      " [ 0.5041224  -0.29121915  0.10341273 -0.09252098]]\n",
      "np.exp( -inputs ) [[1.29792    0.699765   1.3234379  0.95325947]\n",
      " [1.655532   0.7473518  1.1089491  0.91163015]]\n",
      "inputs: [[ 0.          0.00707659  0.3942782   0.4013548 ]\n",
      " [ 0.         -1.1225811  -1.0796583  -2.2022395 ]]\n",
      "1-inputs: [[1.         0.9929234  0.60572183 0.5986452 ]\n",
      " [1.         2.122581   2.0796583  3.2022395 ]]\n",
      "Epoch: 54 / 100, Error: 1.8203014084026687\n",
      "-inputs: [[ 0.38536596  0.12062971 -0.03240073 -0.84403217]\n",
      " [ 0.62221277  1.5176177   1.7909002   2.6239433 ]]\n",
      "np.exp( -inputs ) [[ 1.4701521   1.1282071   0.96811855  0.42997327]\n",
      " [ 1.8630459   4.5613456   5.994847   13.789995  ]]\n",
      "-inputs: [[ 0.2607736  -0.35654452  0.28043067 -0.04698475]\n",
      " [ 0.5042193  -0.28807944  0.10502747 -0.09012181]]\n",
      "np.exp( -inputs ) [[1.2979338  0.7000913  1.3236998  0.954102  ]\n",
      " [1.6556923  0.749702   1.1107411  0.91381985]]\n",
      "inputs: [[ 0.          0.00918916  0.39401457  0.40320373]\n",
      " [ 0.         -1.2182208  -1.1620708  -2.3802915 ]]\n",
      "1-inputs: [[1.        0.9908109 0.6059854 0.5967963]\n",
      " [1.        2.2182207 2.1620708 3.3802915]]\n",
      "Epoch: 55 / 100, Error: 1.8206600958783365\n",
      "-inputs: [[ 0.38569754  0.11880939 -0.03180495 -0.84558827]\n",
      " [ 0.67783237  1.6836039   1.9425123   2.885922  ]]\n",
      "np.exp( -inputs ) [[ 1.4706397   1.1261553   0.96869546  0.42930472]\n",
      " [ 1.9696038   5.3849277   6.9762554  17.92008   ]]\n",
      "-inputs: [[ 0.26090586 -0.35608947  0.28061047 -0.04620107]\n",
      " [ 0.5046698  -0.28480133  0.10671614 -0.0881016 ]]\n",
      "np.exp( -inputs ) [[1.2981055  0.70040995 1.3239378  0.95484996]\n",
      " [1.6564385  0.7521637  1.1126184  0.9156679 ]]\n",
      "inputs: [[ 0.          0.01134108  0.39375037  0.40509143]\n",
      " [ 0.         -1.3285873  -1.2580632  -2.5866504 ]]\n",
      "1-inputs: [[1.         0.9886589  0.60624963 0.5949086 ]\n",
      " [1.         2.3285873  2.2580633  3.5866504 ]]\n",
      "Epoch: 56 / 100, Error: 1.821098294460751\n",
      "-inputs: [[ 0.38604727  0.11696485 -0.03119066 -0.84716827]\n",
      " [ 0.74421406  1.8788245   2.1219342   3.194183  ]]\n",
      "np.exp( -inputs ) [[ 1.4711541   1.12408     0.9692908   0.42862698]\n",
      " [ 2.1047866   6.5458055   8.347267   24.39024   ]]\n",
      "-inputs: [[ 0.26115984 -0.35568315  0.28074422 -0.04553786]\n",
      " [ 0.50555456 -0.28147194  0.10841808 -0.08656427]]\n",
      "np.exp( -inputs ) [[1.2984352  0.7006946  1.3241148  0.9554834 ]\n",
      " [1.6579046  0.75467205 1.1145135  0.9170766 ]]\n",
      "inputs: [[ 0.          0.01353535  0.3934858   0.40702116]\n",
      " [ 0.         -1.4574262  -1.3711035  -2.8285298 ]]\n",
      "1-inputs: [[1.         0.9864647  0.6065142  0.59297884]\n",
      " [1.         2.457426   2.3711035  3.8285298 ]]\n",
      "Epoch: 57 / 100, Error: 1.8215843103253535\n",
      "-inputs: [[ 0.38641614  0.1150937  -0.03055716 -0.8487748 ]\n",
      " [ 0.82447565  2.1115122   2.3370252   3.5616999 ]]\n",
      "np.exp( -inputs ) [[ 1.471697    1.1219785   0.96990496  0.4279389 ]\n",
      " [ 2.2806845   8.260723   10.3504     35.223022  ]]\n",
      "-inputs: [[ 0.26152277 -0.3553722   0.2807969  -0.04500934]\n",
      " [ 0.5069648  -0.27822354  0.11004099 -0.08560759]]\n",
      "np.exp( -inputs ) [[1.2989066 0.7009125 1.3241847 0.9559885]\n",
      " [1.6602445 0.7571275 1.1163238 0.9179543]]\n",
      "inputs: [[ 0.          0.01577538  0.39322117  0.40899655]\n",
      " [ 0.         -1.6098523  -1.5059329  -3.1157851 ]]\n",
      "1-inputs: [[1.         0.9842246  0.60677886 0.5910034 ]\n",
      " [1.         2.6098523  2.5059328  4.115785  ]]\n",
      "Epoch: 58 / 100, Error: 1.8220629971970768\n",
      "-inputs: [[ 0.38680524  0.11319332 -0.02990365 -0.8504108 ]\n",
      " [ 0.9230088   2.3932123   2.5988152   4.006657  ]]\n",
      "np.exp( -inputs ) [[ 1.4722697   1.1198485   0.9705391   0.42723942]\n",
      " [ 2.516852   10.948607   13.447796   54.96283   ]]\n",
      "-inputs: [[ 0.2619617  -0.3552077   0.28072977 -0.04461828]\n",
      " [ 0.5089998  -0.2752405   0.11145473 -0.08530706]]\n",
      "np.exp( -inputs ) [[1.2994767  0.7010278  1.3240958  0.9563625 ]\n",
      " [1.6636266  0.75938946 1.1179031  0.91823024]]\n",
      "inputs: [[ 0.          0.01806488  0.39295676  0.41102165]\n",
      " [ 0.         -1.7930193  -1.6691897  -3.462209  ]]\n",
      "1-inputs: [[1.         0.98193514 0.60704327 0.58897835]\n",
      " [1.         2.7930193  2.6691897  4.4622087 ]]\n",
      "Epoch: 59 / 100, Error: 1.8224495652859476\n",
      "-inputs: [[ 0.38721576  0.11126111 -0.02922937 -0.8520793 ]\n",
      " [ 1.0461702   2.7405639   2.9232113   4.555243  ]]\n",
      "np.exp( -inputs ) [[ 1.4728742   1.1176867   0.9711937   0.42652714]\n",
      " [ 2.8467276  15.495721   18.600925   95.12987   ]]\n",
      "-inputs: [[ 0.2624156  -0.3552357   0.2805071  -0.04435188]\n",
      " [ 0.511761   -0.27275708  0.11249053 -0.08569604]]\n",
      "np.exp( -inputs ) [[1.3000667  0.7010082  1.3238009  0.9566173 ]\n",
      " [1.6682262  0.7612776  1.1190617  0.91787314]]\n",
      "inputs: [[ 0.          0.02040761  0.392693    0.41310063]\n",
      " [ 0.         -2.0172093  -1.8704245  -3.8876338 ]]\n",
      "1-inputs: [[1.         0.9795924  0.60730696 0.5868994 ]\n",
      " [1.         3.0172093  2.8704245  4.887634  ]]\n",
      "Epoch: 60 / 100, Error: 1.822631282452421\n",
      "-inputs: [[ 0.38764894  0.10929495 -0.02853361 -0.85378283]\n",
      " [ 1.2034549   3.1783152   3.3338895   5.2463884 ]]\n",
      "np.exp( -inputs ) [[  1.4735124    1.1154913    0.97186965   0.42580113]\n",
      " [  3.3316073   24.006271    28.047218   189.87926   ]]\n",
      "-inputs: [[ 0.26278904 -0.35548198  0.280107   -0.04418053]\n",
      " [ 0.51533926 -0.27103713  0.11295137 -0.08674675]]\n",
      "np.exp( -inputs ) [[1.3005524  0.7008356  1.3232714  0.95678127]\n",
      " [1.6742064  0.76258814 1.1195775  0.9169092 ]]\n",
      "inputs: [[ 0.          0.02280696  0.39243042  0.4152374 ]\n",
      " [ 0.         -2.297676   -2.1238182  -4.4214945 ]]\n",
      "1-inputs: [[1.         0.97719306 0.6075696  0.5847626 ]\n",
      " [1.         3.297676   3.1238182  5.4214945 ]]\n",
      "Epoch: 61 / 100, Error: 1.8224791741167232\n",
      "-inputs: [[ 0.38810602  0.1072937  -0.02781567 -0.8555232 ]\n",
      " [ 1.4095811   3.7446747   3.8674216   6.1401534 ]]\n",
      "np.exp( -inputs ) [[1.4741861e+00 1.1132611e+00 9.7256762e-01 4.2506075e-01]\n",
      " [4.0942397e+00 4.2295246e+01 4.7818928e+01 4.6412476e+02]]\n",
      "-inputs: [[ 0.2629541  -0.35593534  0.27953565 -0.04406187]\n",
      " [ 0.5197873  -0.2703254   0.11264309 -0.08836043]]\n",
      "np.exp( -inputs ) [[1.3007671 0.7005179 1.3225156 0.9568948]\n",
      " [1.6816698 0.7631311 1.1192324 0.9154309]]\n",
      "inputs: [[ 0.          0.0252653   0.39216956  0.41743487]\n",
      " [ 0.         -2.6579094  -2.4512239  -5.1091332 ]]\n",
      "1-inputs: [[1.        0.9747347 0.6078304 0.5825651]\n",
      " [1.        3.6579094 3.4512239 6.1091332]]\n",
      "Epoch: 62 / 100, Error: 1.8218765306435794\n",
      "-inputs: [[ 0.38858822  0.10525807 -0.02707496 -0.85730034]\n",
      " [ 1.6884042   4.5013285   4.5828757   7.333438  ]]\n",
      "np.exp( -inputs ) [[1.4748970e+00 1.1109973e+00 9.7328830e-01 4.2430601e-01]\n",
      " [5.4108391e+00 9.0136795e+01 9.7795212e+01 1.5306349e+03]]\n",
      "-inputs: [[ 0.262771   -0.35653907  0.27883527 -0.04395069]\n",
      " [ 0.5250573  -0.2707663   0.1114307  -0.09037679]]\n",
      "np.exp( -inputs ) [[1.3005289  0.7000951  1.3215896  0.9570011 ]\n",
      " [1.6905557  0.76279473 1.1178763  0.91358685]]\n",
      "inputs: [[ 0.          0.02778312  0.39191106  0.4196942 ]\n",
      " [ 0.         -3.13574    -2.8878548  -6.023595  ]]\n",
      "1-inputs: [[1.         0.9722169  0.60808897 0.5803058 ]\n",
      " [1.         4.1357403  3.8878548  7.023595  ]]\n",
      "Epoch: 63 / 100, Error: 1.8207671962508467\n",
      "-inputs: [[ 0.38909656  0.10319152 -0.02631098 -0.85911125]\n",
      " [ 2.080774    5.553516    5.5810566   8.991436  ]]\n",
      "np.exp( -inputs ) [[1.4756470e+00 1.1087036e+00 9.7403216e-01 4.2353830e-01]\n",
      " [8.0106668e+00 2.5814359e+02 2.6535181e+02 8.0339854e+03]]\n",
      "-inputs: [[ 0.26214126 -0.35720545  0.2780766  -0.0438102 ]\n",
      " [ 0.5308649  -0.27231264  0.10931432 -0.09260911]]\n",
      "np.exp( -inputs ) [[1.29971    0.6996287  1.3205873  0.9571357 ]\n",
      " [1.7004024  0.76161605 1.115513   0.91154975]]\n",
      "inputs: [[ 0.          0.03035801  0.39165542  0.42201343]\n",
      " [ 0.         -3.7955575  -3.4936657  -7.289223  ]]\n",
      "1-inputs: [[1.         0.969642   0.60834455 0.5779866 ]\n",
      " [1.         4.7955575  4.4936657  8.289223  ]]\n",
      "Epoch: 64 / 100, Error: 1.819212964445648\n",
      "-inputs: [[ 0.3896318   0.10110082 -0.02552339 -0.86094964]\n",
      " [ 2.661682    7.09375     7.046398   11.416104  ]]\n",
      "np.exp( -inputs ) [[1.4764371e+00 1.1063882e+00 9.7479957e-01 4.2276043e-01]\n",
      " [1.4320355e+01 1.2044160e+03 1.1487139e+03 9.0771836e+04]]\n",
      "-inputs: [[ 0.2610901  -0.35785294  0.27733    -0.04361856]\n",
      " [ 0.5364436  -0.27468157  0.10648534 -0.09489471]]\n",
      "np.exp( -inputs ) [[1.2983446  0.69917595 1.3196018  0.95731914]\n",
      " [1.7099149  0.759814   1.1123617  0.90946865]]\n",
      "inputs: [[ 0.          0.03298394  0.39140308  0.42438704]\n",
      " [ 0.         -4.754884   -4.3780994  -9.132983  ]]\n",
      "1-inputs: [[ 1.          0.96701604  0.6085969   0.57561296]\n",
      " [ 1.          5.754884    5.3780994  10.132983  ]]\n",
      "Epoch: 65 / 100, Error: 1.8174417504697802\n",
      "-inputs: [[ 0.39019436  0.0989961  -0.02471194 -0.86280537]\n",
      " [ 3.5818481   9.507641    9.348372   15.211803  ]]\n",
      "np.exp( -inputs ) [[1.4772679e+00 1.1040621e+00 9.7559088e-01 4.2197666e-01]\n",
      " [3.5939903e+01 1.3462197e+04 1.1480123e+04 4.0401945e+06]]\n",
      "-inputs: [[ 0.25982127 -0.3584415   0.27663368 -0.04336683]\n",
      " [ 0.54033726 -0.27744013  0.10329002 -0.09712547]]\n",
      "np.exp( -inputs ) [[1.2966982  0.6987645  1.3186833  0.9575601 ]\n",
      " [1.7165856  0.7577208  1.1088129  0.90744215]]\n",
      "inputs: [[  0.           0.03565121   0.39115417   0.42680538]\n",
      " [  0.          -6.248608    -5.7599077  -12.008516  ]]\n",
      "1-inputs: [[ 1.          0.9643488   0.60884583  0.5731946 ]\n",
      " [ 1.          7.248608    6.7599077  13.008516  ]]\n",
      "Epoch: 66 / 100, Error: 1.815830263704897\n",
      "-inputs: [[ 0.39078426  0.09688933 -0.02387646 -0.8646666 ]\n",
      " [ 5.183342   13.667515   13.322898   21.744707  ]]\n",
      "np.exp( -inputs ) [[1.4781395e+00 1.1017385e+00 9.7640628e-01 4.2119196e-01]\n",
      " [1.7827763e+02 8.6243481e+05 6.1102794e+05 2.7771945e+09]]\n",
      "-inputs: [[ 0.25861788 -0.3589695   0.27599084 -0.04305506]\n",
      " [ 0.5409745  -0.28021643  0.10006571 -0.09922928]]\n",
      "np.exp( -inputs ) [[1.2951388 0.6983956 1.3178358 0.9578587]\n",
      " [1.7176797 0.7556202 1.1052436 0.9055351]]\n",
      "inputs: [[  0.           0.03834788   0.3909086    0.42925647]\n",
      " [  0.          -8.806988    -8.132939   -16.939926  ]]\n",
      "1-inputs: [[ 1.          0.9616521   0.6090914   0.57074356]\n",
      " [ 1.          9.806988    9.132939   17.939926  ]]\n",
      "Epoch: 67 / 100, Error: 1.814733980627886\n",
      "-inputs: [[ 3.9140147e-01  9.4791368e-02 -2.3016691e-02 -8.6652201e-01]\n",
      " [ 8.3854876e+00  2.1910583e+01  2.1209965e+01  3.4672699e+01]]\n",
      "np.exp( -inputs ) [[1.4790522e+00 1.0994295e+00 9.7724622e-01 4.2041123e-01]\n",
      " [4.3829946e+03 3.2782758e+09 1.6269367e+09 1.1433043e+15]]\n",
      "-inputs: [[ 0.25758997 -0.35944706  0.27539217 -0.04269017]\n",
      " [ 0.5386311  -0.2828268   0.09699932 -0.10113537]]\n",
      "np.exp( -inputs ) [[1.2938082  0.69806224 1.3170471  0.95820826]\n",
      " [1.7136594  0.75365025 1.1018597  0.9038106 ]]\n",
      "inputs: [[  0.           0.04106306   0.39066604   0.4317291 ]\n",
      " [  0.         -13.847912   -12.81786    -26.665771  ]]\n",
      "1-inputs: [[ 1.         0.9589369  0.609334   0.5682709]\n",
      " [ 1.        14.847912  13.81786   27.665771 ]]\n",
      "Epoch: 68 / 100, Error: 1.8141470962045227\n",
      "-inputs: [[ 3.9204615e-01  9.2708901e-02 -2.2132188e-02 -8.6836469e-01]\n",
      " [ 1.6350895e+01  4.2254333e+01  4.0694752e+01  6.6535828e+01]]\n",
      "np.exp( -inputs ) [[1.4800060e+00 1.0971422e+00 9.7811097e-01 4.1963720e-01]\n",
      " [1.2621281e+07 2.2429720e+18 4.7152652e+17 7.8730458e+28]]\n",
      "-inputs: [[ 0.25664663 -0.35988253  0.2748295  -0.0422805 ]\n",
      " [ 0.53551006 -0.28520876  0.09415692 -0.10279119]]\n",
      "np.exp( -inputs ) [[1.2925882  0.6977583  1.3163062  0.95860094]\n",
      " [1.7083193  0.7518572  1.0987321  0.9023153 ]]\n",
      "inputs: [[ 0.0000000e+00  4.3790221e-02  3.9042622e-01  4.3421644e-01]\n",
      " [ 0.0000000e+00 -2.6226254e+01 -2.4337240e+01 -5.0563492e+01]]\n",
      "1-inputs: [[ 1.          0.9562098   0.6095738   0.56578356]\n",
      " [ 1.         27.226254   25.33724    51.56349   ]]\n",
      "Epoch: 69 / 100, Error: 1.8137268702427294\n",
      "-inputs: [[ 3.9271891e-01  9.0644553e-02 -2.1222115e-02 -8.7019169e-01]\n",
      " [ 4.5105911e+01  1.1522572e+02  1.1062900e+02  1.8068646e+02]]\n",
      "np.exp( -inputs ) [[1.4810020e+00 1.0948797e+00 9.7900146e-01 4.1887125e-01]\n",
      " [3.8837240e+19           inf           inf           inf]]\n",
      "-inputs: [[ 0.25573564 -0.36028096  0.27429783 -0.04183139]\n",
      " [ 0.53255916 -0.28736302  0.09153804 -0.10419816]]\n",
      "np.exp( -inputs ) [[1.2914113  0.6974803  1.3156066  0.9590315 ]\n",
      " [1.7032858  0.75023925 1.0958585  0.90104675]]\n",
      "inputs: [[ 0.0000000e+00  4.6527341e-02  3.9018890e-01  4.3671626e-01]\n",
      " [ 0.0000000e+00 -7.0442627e+01 -6.5516472e+01 -1.3595911e+02]]\n",
      "1-inputs: [[  1.           0.9534727    0.60981107   0.56328374]\n",
      " [  1.          71.44263     66.51647    136.9591    ]]\n",
      "Epoch: 70 / 100, Error: 1.8133212186867036\n",
      "-inputs: [[ 3.93420458e-01  8.85996372e-02 -2.02856064e-02 -8.72001648e-01]\n",
      " [ 2.53954987e+02  6.42895935e+02  6.16484253e+02  1.00536285e+03]]\n",
      "np.exp( -inputs ) [[1.4820412 1.0926431 0.9799188 0.4181138]\n",
      " [      inf       inf       inf       inf]]\n",
      "-inputs: [[ 0.2548514  -0.36064565  0.27379382 -0.04134649]\n",
      " [ 0.5298026  -0.28930977  0.08912209 -0.10537833]]\n",
      "np.exp( -inputs ) [[1.2902699  0.69722605 1.3149437  0.95949656]\n",
      " [1.6985971  0.7487802  1.0932142  0.89998394]]\n",
      "inputs: [[ 0.0000000e+00  4.9273804e-02  3.8995394e-01  4.3922776e-01]\n",
      " [ 0.0000000e+00 -3.8926376e+02 -3.6252267e+02 -7.5178644e+02]]\n",
      "1-inputs: [[1.0000000e+00 9.5072621e-01 6.1004603e-01 5.6077224e-01]\n",
      " [1.0000000e+00 3.9026376e+02 3.6352267e+02 7.5278644e+02]]\n",
      "Epoch: 71 / 100, Error: 1.8129217635734145\n",
      "-inputs: [[ 3.9415151e-01  8.6575426e-02 -1.9321799e-02 -8.7379313e-01]\n",
      " [ 6.6729526e+03  1.6828176e+04  1.6133797e+04  2.6288957e+04]]\n",
      "np.exp( -inputs ) [[1.4831251  1.0904336  0.9808637  0.41736543]\n",
      " [       inf        inf        inf        inf]]\n",
      "-inputs: [[ 0.25399107 -0.36097962  0.2733144  -0.040829  ]\n",
      " [ 0.5272219  -0.291068    0.08688959 -0.10635257]]\n",
      "np.exp( -inputs ) [[1.2891603  0.69699323 1.3143133  0.9599932 ]\n",
      " [1.6942191  0.74746484 1.0907762  0.89910764]]\n",
      "inputs: [[ 0.0000000e+00  5.2029051e-02  3.8972118e-01  4.4175023e-01]\n",
      " [ 0.0000000e+00 -1.0155547e+04 -9.4608369e+03 -1.9616383e+04]]\n",
      "1-inputs: [[1.0000000e+00 9.4797093e-01 6.1027884e-01 5.5824977e-01]\n",
      " [1.0000000e+00 1.0156547e+04 9.4618369e+03 1.9617383e+04]]\n",
      "Epoch: 72 / 100, Error: 1.8125268209356458\n",
      "-inputs: [[ 3.9491272e-01  8.4573194e-02 -1.8329859e-02 -8.7556458e-01]\n",
      " [ 4.4022115e+06  1.1096590e+07  1.0638936e+07  1.7333314e+07]]\n",
      "np.exp( -inputs ) [[1.4842546  1.0882524  0.98183703 0.41662672]\n",
      " [       inf        inf        inf        inf]]\n",
      "-inputs: [[ 0.25315198 -0.36128557  0.27285683 -0.04028189]\n",
      " [ 0.5248     -0.29265535  0.08482277 -0.10714006]]\n",
      "np.exp( -inputs ) [[1.288079   0.69677997 1.3137121  0.9605186 ]\n",
      " [1.6901208  0.74627924 1.0885241  0.8983998 ]]\n",
      "inputs: [[ 0.0000000e+00  5.4792508e-02  3.8949046e-01  4.4428295e-01]\n",
      " [ 0.0000000e+00 -6.6943790e+06 -6.2367240e+06 -1.2931103e+07]]\n",
      "1-inputs: [[1.0000000e+00 9.4520748e-01 6.1050951e-01 5.5571705e-01]\n",
      " [1.0000000e+00 6.6943800e+06 6.2367250e+06 1.2931104e+07]]\n",
      "Epoch: 73 / 100, Error: 1.8121361550588668\n",
      "-inputs: [[ 3.9570481e-01  8.2594201e-02 -1.7308891e-02 -8.7731475e-01]\n",
      " [ 1.9214884e+12  4.8440740e+12  4.6443738e+12  7.5669591e+12]]\n",
      "np.exp( -inputs ) [[1.4854306  1.0861009  0.98284006 0.4158982 ]\n",
      " [       inf        inf        inf        inf]]\n",
      "-inputs: [[ 0.2523318  -0.361566    0.2724186  -0.03970787]\n",
      " [ 0.52252156 -0.29408756  0.08290556 -0.10775822]]\n",
      "np.exp( -inputs ) [[1.287023   0.69658464 1.3131366  0.9610701 ]\n",
      " [1.6862742  0.7452112  1.0864393  0.8978446 ]]\n",
      "inputs: [[ 0.0000000e+00  5.7563603e-02  3.8926157e-01  4.4682518e-01]\n",
      " [ 0.0000000e+00 -2.9225855e+12 -2.7228853e+12 -5.6454708e+12]]\n",
      "1-inputs: [[1.0000000e+00 9.4243640e-01 6.1073840e-01 5.5317485e-01]\n",
      " [1.0000000e+00 2.9225855e+12 2.7228853e+12 5.6454708e+12]]\n",
      "Epoch: 74 / 100, Error: 1.8117488920994278\n",
      "-inputs: [[ 3.9652845e-01  8.0639713e-02 -1.6258061e-02 -8.7904203e-01]\n",
      " [ 3.6847000e+23  9.2903813e+23  8.9075429e+23  1.4513224e+24]]\n",
      "np.exp( -inputs ) [[1.4866546  1.0839802  0.98387337 0.41518044]\n",
      " [       inf        inf        inf        inf]]\n",
      "-inputs: [[ 0.2515283  -0.36182308  0.27199745 -0.0391093 ]\n",
      " [ 0.52037257 -0.295379    0.08112329 -0.10822266]]\n",
      "np.exp( -inputs ) [[1.2859894  0.6964056  1.3125836  0.96164554]\n",
      " [1.6826544  0.74424946 1.0845046  0.8974278 ]]\n",
      "inputs: [[ 0.0000000e+00  6.0341753e-02  3.8903439e-01  4.4937614e-01]\n",
      " [ 0.0000000e+00 -5.6056813e+23 -5.2228429e+23 -1.0828524e+24]]\n",
      "1-inputs: [[1.0000000e+00 9.3965822e-01 6.1096561e-01 5.5062389e-01]\n",
      " [1.0000000e+00 5.6056813e+23 5.2228429e+23 1.0828524e+24]]\n",
      "Epoch: 75 / 100, Error: 1.811364399917938\n",
      "-inputs: [[ 0.39738435  0.07871098 -0.01517653 -0.8807452 ]\n",
      " [        nan         nan         nan         nan]]\n",
      "np.exp( -inputs ) [[1.4879277  1.0818917  0.9849381  0.41447395]\n",
      " [       nan        nan        nan        nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[0.         0.06312638 0.38880876 0.45193514]\n",
      " [       nan        nan        nan        nan]]\n",
      "1-inputs: [[1.        0.9368736 0.6111913 0.5480648]\n",
      " [      nan       nan       nan       nan]]\n",
      "Epoch: 76 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 77 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 78 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 79 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 80 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 81 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 82 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 83 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 84 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 85 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 86 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 87 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 88 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 89 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 90 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 91 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 92 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 93 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 94 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 95 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 96 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 97 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 98 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 99 / 100, Error: nan\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "1-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "Epoch: 100 / 100, Error: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_419599/4293650904.py:78: RuntimeWarning: overflow encountered in exp\n",
      "  print( \"np.exp( -inputs )\",np.exp( -inputs  ) );\n",
      "/tmp/ipykernel_419599/4293650904.py:79: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / ( 1 + np.exp( -inputs ) );\n",
      "/tmp/ipykernel_419599/4293650904.py:73: RuntimeWarning: overflow encountered in multiply\n",
      "  return inputs * ( 1 - inputs );\n",
      "/home/protim/Documents/venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "nn.train( x_train, y_train );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "-inputs: [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "np.exp( -inputs ) [[nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print( nn.predict( x_test ) );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
