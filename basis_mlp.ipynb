{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "from tqdm import trange;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.1\n"
     ]
    }
   ],
   "source": [
    "print( np.__version__ );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_data():\n",
    "    input_array = np.array( [ [ 0.0, 0.0 ], [ 0.0, 1.0 ], [ 1.0, 0.0 ], [ 1.0, 1.0 ] ] );\n",
    "    output_array = np.array( [ [ 0.0 ], [ 1.0 ], [ 1.0 ], [ 0.0 ] ] );\n",
    "    return ( input_array.astype('float32'), output_array.astype('float32') ),\\\n",
    "( input_array.astype('float32'), output_array.astype('float32') );\n",
    "\n",
    "def load_data( name ):\n",
    "    if name == \"xor\":\n",
    "        return xor_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss( object ):\n",
    "    def __init__( self, name : str ):\n",
    "        self.name = name;\n",
    "\n",
    "    def __call__( self, y_pred, y_true, deriv=False ):\n",
    "        if self.name == \"mse\":\n",
    "            return np.mean( ( y_pred - y_true ) ** 2 );\n",
    "    \n",
    "        elif self.name == \"cross_entropy\" and deriv == False:\n",
    "            return -np.mean( y_true * np.log( y_pred ) + ( 1 - y_true ) * np.log( 1 - y_pred ) );\n",
    "        \n",
    "        else:\n",
    "            raise ValueError( \"Invalid loss function\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(object):\n",
    "    \"\"\"\n",
    "    Gradient Descent optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters: dict):\n",
    "        self.parameters = parameters;\n",
    "        self.name = \"Gradient Descent\";\n",
    "    \n",
    "    def minimize( self, trainable_parameters, loss_obj: Loss ):\n",
    "        \"\"\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer( object ):\n",
    "    \"\"\"\n",
    "    Base class for the Layer class.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name : str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Base Layer class.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            node_no : int\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.params : dict\n",
    "            self.node_no : int\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "\n",
    "        \"\"\"\n",
    "        self.hyperparams = hyperparams;\n",
    "        self.name = name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputLayer( BaseLayer ):\n",
    "    \"\"\"\n",
    "    Input layer for the perceptron.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name: str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Input Layer class.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            node_no : int\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.bias : array\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super( InputLayer, self ).__init__( hyperparams, name );\n",
    "        self.node_no = hyperparams['input_units'];\n",
    "    \n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Mirror the inputs.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return inputs;\n",
    "\n",
    "    def __rshift__( self, other ):\n",
    "        \"\"\"\n",
    "        Overwrite the right shift operator to connect the layers.\n",
    "\n",
    "        args:\n",
    "            other : object\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return NeuralNetwork( self, other );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer( BaseLayer ):\n",
    "    \"\"\"\n",
    "    Layer class for the perceptron.\n",
    "    \"\"\"\n",
    "    def __init__( self, hyperparams : dict, name: str, transfer: str  ):\n",
    "        \"\"\"\n",
    "        Constructor for the Layer class.\n",
    "\n",
    "        args:\n",
    "            name : str\n",
    "            params : dict\n",
    "            node_no : int\n",
    "            transfer : str\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.name : str\n",
    "            self.transfer : str\n",
    "            self.inputs : object\n",
    "            self.outputs : object\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        super( Layer, self ).__init__( hyperparams, name );\n",
    "        self.transfer = transfer;\n",
    "\n",
    "        self.inputs = None;\n",
    "        self.outputs = None;\n",
    "    \n",
    "        if \"hidden\" in name:\n",
    "            self.node_no = hyperparams['hidden_units'];\n",
    "        else:\n",
    "            self.node_no = hyperparams['output_units'];\n",
    "        \n",
    "        #create self.bias to be an array of size node_no with random values from a normal distribution between -1 and 1\n",
    "        self.bias = np.random.uniform( -1, 1, self.node_no );\n",
    "        \n",
    "        \n",
    "    def __rshift__( self, other ):\n",
    "        \"\"\"\n",
    "        Overwrite the right shift operator to connect the layers.\n",
    "\n",
    "        args:\n",
    "            other : object\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return NeuralNetwork( self, other );\n",
    "    \n",
    "    def transfer_fx( self, inputs ):\n",
    "        \"\"\"\n",
    "        Transfer function for the layer.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # implement the sigmoid transfer function\n",
    "        return 1 / ( 1 + np.exp( -inputs ) );\n",
    "\n",
    "\n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Calculate the output with the activation function and inputs.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            self.outputs : array\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        #self.activated = self.transfer_fx( self.inputs.output( inputs ) + self.bias );\n",
    "        self.activated = self.transfer_fx( inputs + self.bias );\n",
    "        return self.activated;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightLayer( BaseLayer):\n",
    "    \"\"\"\n",
    "    Weight layer for the perceptron.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__( self, src : Layer, dest : Layer ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for the weight layer.\n",
    "\n",
    "        args:\n",
    "            params : dict\n",
    "            src : Layer\n",
    "            dest : Layer\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.src : Layer\n",
    "            self.dest : Layer\n",
    "            self.input_size : tuple\n",
    "            self.output_size : tuple\n",
    "            self.name : str\n",
    "            self.weights : array\n",
    "\n",
    "        raises: \n",
    "            None\n",
    "        \"\"\"\n",
    "        self.src = src;\n",
    "        self.dest = dest;\n",
    "\n",
    "        #print( f\"src: {src.node_no}, dest: {dest.node_no}\" );\n",
    "    \n",
    "        #self.weights = np.random.randn( self.src.node_no, self.dest.node_no );\n",
    "        #create self.weights to be a matrix of size src.node_no x dest.node_no with random values from a uniform distribution between -1 and 1\n",
    "        self.weights = np.random.uniform( -1, 1, ( self.src.node_no, self.dest.node_no ) );\n",
    "        self.name    = \"W_%s_%s_layer\" % ( self.src.name, self.dest.name );\n",
    "\n",
    "        self.src.outputs = self;\n",
    "        self.dest.inputs = self;\n",
    "\n",
    "\n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Matrix multiplication between the inputs and the weights.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"        \n",
    "        return self.src.output( inputs ) @ self.weights;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork( object ):\n",
    "    \"\"\"\n",
    "    This class respresents a Neural Networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__( self, layer0, layer1 ):\n",
    "        \"\"\"\n",
    "        Constructor for the Neural Network class.\n",
    "        Creates a network with an input layer, layer0 and an output layer, layer1.\n",
    "\n",
    "        args:\n",
    "            layer0 : object\n",
    "            layer1 : object\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            self.hyperparams : dict\n",
    "            self.layers : list\n",
    "            self.input_layer : object\n",
    "            self.output_layer : object\n",
    "            self.weights : list\n",
    "            self.loss_fn : object\n",
    "            self.optimizer : object\n",
    "\n",
    "        raises:\n",
    "            None \n",
    "        \"\"\"\n",
    "        # hyperparameters dictionary\n",
    "        self.hyperparams = layer0.hyperparams;\n",
    "\n",
    "        # layers\n",
    "        self.layers = [ layer0, layer1 ];\n",
    "        self.input_layer = layer0;\n",
    "        self.output_layer = self.layers[-1];\n",
    "\n",
    "        # weights\n",
    "        self.weights = [ WeightLayer( layer0, layer1 ) ];\n",
    "\n",
    "        # loss function\n",
    "        self.loss_fn = None;\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = None;\n",
    "\n",
    "        # trainable parameters\n",
    "        self.trainable_parameters = {};\n",
    "        for weight in self.weights:\n",
    "            self.trainable_parameters[weight.name] = weight.weights;\n",
    "        for layer in self.layers[1:]:\n",
    "            self.trainable_parameters[layer.name] = layer.bias;\n",
    "    \n",
    "    def summary( self ):\n",
    "        \"\"\"\n",
    "        Print the summary of the network.\n",
    "\n",
    "        args:\n",
    "            None\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print( \"-------\" );\n",
    "        print( \"| Summary |\" );\n",
    "        print( \"-------\" );\n",
    "        print( f\"Input Layer: { self.input_layer.node_no }\" );\n",
    "        print( f\"Hidden Layer: { self.layers[1].node_no }\" );\n",
    "        print( f\"Output Layer: { self.output_layer.node_no }\" );\n",
    "    \n",
    "        print( \"-------\" );\n",
    "        print( \"| Weights |\" );\n",
    "        print( \"-------\" );\n",
    "        for weight_obj in self.weights:\n",
    "            print( f\"{weight_obj.name}: \\n {weight_obj.weights} , {weight_obj.weights.shape}\" );\n",
    "        \n",
    "        print( \"-------\" );\n",
    "        print( \"| Bias |\" );\n",
    "        print( \"------\" );\n",
    "        for layer_obj in self.layers:\n",
    "            if hasattr( layer_obj, 'bias' ):\n",
    "                print( f\"{layer_obj.name}: \\n {layer_obj.bias}, {layer_obj.bias.shape}\" );\n",
    "            else:\n",
    "                print( f\"{layer_obj.name}: \" );\n",
    "        \n",
    "        print( \"---------------\" );\n",
    "        print( \"| Hyperparameters |\" );\n",
    "        print( \"---------------\" );\n",
    "        print( f\"Epochs: {self.hyperparams['epochs']}\" );\n",
    "        print( f\"Learning Rate: {self.hyperparams['lr']}\" );\n",
    "        print( f\"Minibatch Size: {self.hyperparams['minibatch_size']}\" );\n",
    "        print( \"---------------\" );\n",
    "\n",
    "        print( \"---------------\" );\n",
    "        print( f\"| Loss Function | : {self.loss_fn.name}\" );\n",
    "        print( \"---------------\" );\n",
    "        \n",
    "        print( \"---------------\" );\n",
    "        print( f\"| Optimizer | : {self.optimizer.name}\" );\n",
    "        print( \"---------------\" );\n",
    "\n",
    "        print( \"---------------\" );\n",
    "        print( \"| Trainable Parameters | \")\n",
    "        print( \"---------------\" );\n",
    "        print( self.trainable_parameters );\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def __rshift__( self, other ):\n",
    "        \"\"\"\n",
    "        Overwrite the right shift operator to add a layer to the network\n",
    "        \"\"\"\n",
    "        if isinstance( other, Layer ) or isinstance( other, InputLayer ):\n",
    "            self.weights.append( WeightLayer( self.layers[-1], other ) );\n",
    "            self.layers.append( other );\n",
    "            self.output_layer = self.layers[-1];\n",
    "\n",
    "            self.trainable_parameters[self.weights[-1].name] = self.weights[-1].weights;\n",
    "            self.trainable_parameters[other.name] = other.bias;\n",
    "\n",
    "            return self;\n",
    "    \n",
    "        if isinstance( other, Loss ):\n",
    "            self.loss_fn = other;\n",
    "            return self;\n",
    "\n",
    "        if isinstance( other, GradientDescent ):\n",
    "            self.optimizer = other;\n",
    "            return self;\n",
    "\n",
    "        else:\n",
    "            print( type( other ) );\n",
    "\n",
    "    def output( self, inputs ):\n",
    "        \"\"\"\n",
    "        Calculate the output of the network.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return self.output_layer.output( inputs );\n",
    "\n",
    "    def forward( self, inputs ):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        args:\n",
    "            inputs : array\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for i in range( len( self.weights ) ):\n",
    "            pre_activation = self.weights[i].output( inputs );\n",
    "            activated_weights = self.layers[i + 1].output( pre_activation );\n",
    "            inputs = activated_weights;\n",
    "\n",
    "        return activated_weights;\n",
    "\n",
    "    def predict( self, X ):\n",
    "        \"\"\"\n",
    "        Predict the output of the network.\n",
    "\n",
    "        args:\n",
    "            X : array\n",
    "\n",
    "        returns:\n",
    "            array\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        return self.forward( X );\n",
    "\n",
    "    def train( self, X, y ):\n",
    "        \"\"\"\n",
    "        Train the network.\n",
    "\n",
    "        args:\n",
    "            X : array\n",
    "            y : array\n",
    "            epochs : int\n",
    "            lr : float\n",
    "\n",
    "        returns:\n",
    "            None\n",
    "\n",
    "        attributes:\n",
    "            None\n",
    "\n",
    "        raises:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for epoch in trange( self.hyperparams['epochs'] ):\n",
    "            # forward pass\n",
    "            logits = self.forward( X );\n",
    "\n",
    "            # calculate the loss\n",
    "            fwd_loss = self.loss_fn( logits, y, deriv=False );\n",
    "            print( f\"Epoch: { epoch + 1 }, Loss: { fwd_loss }\" );\n",
    "\n",
    "\n",
    "            # backward pass\n",
    "            #trainable_parameters = self.optimizer.minimize( logits, self.trainable_parameters, self.loss_fn );\n",
    "            \n",
    "            # update the weights and biases\n",
    "            #self.trainable_parameters = trainable_parameters;\n",
    "            #for index in range( len ( self.weights ) ):\n",
    "                #self.weights[index].weights = self.trainable_parameters['weights'][index][1];\n",
    "                #self.layers[index + 1].bias = self.trainable_parameters['biases'][index][1];\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # model hyperparameters\n",
    "    \"input_units\" : 2,\n",
    "    \"hidden_units\" : 2,\n",
    "    \"output_units\" : 1,\n",
    "\n",
    "    # optimizer hyperparameters\n",
    "    \"lr\" : 0.01,\n",
    "\n",
    "    # training hyperparameters\n",
    "    \"epochs\" : 1,\n",
    "    \"minibatch_size\" : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = load_data( \"xor\" );\n",
    "x_train, y_train = training[0], training[1];\n",
    "x_test, y_test = testing[0], testing[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: \n",
      " [[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]], (4, 2)\n",
      "Labels: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], (4, 1)\n"
     ]
    }
   ],
   "source": [
    "print( f\"Training set: \\n {x_train}, {x_train.shape}\" );\n",
    "print( f\"Labels: \\n {y_train}, {y_train.shape}\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = InputLayer( params, \"input\" );\n",
    "hidden_layer = Layer( params, \"hidden\", \"sigmoid\" );\n",
    "output_layer = Layer( params, \"output\", \"sigmoid\" );\n",
    "\n",
    "loss = Loss( \"cross_entropy\" );\n",
    "optimizer = GradientDescent( params );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "| Summary |\n",
      "-------\n",
      "Input Layer: 2\n",
      "Hidden Layer: 2\n",
      "Output Layer: 1\n",
      "-------\n",
      "| Weights |\n",
      "-------\n",
      "W_input_hidden_layer: \n",
      " [[-0.66157275 -0.40900101]\n",
      " [-0.63631169 -0.99798354]] , (2, 2)\n",
      "W_hidden_output_layer: \n",
      " [[0.30716018]\n",
      " [0.79441294]] , (2, 1)\n",
      "-------\n",
      "| Bias |\n",
      "------\n",
      "input: \n",
      "hidden: \n",
      " [ 0.59309058 -0.02415929], (2,)\n",
      "output: \n",
      " [-0.04661841], (1,)\n",
      "---------------\n",
      "| Hyperparameters |\n",
      "---------------\n",
      "Epochs: 1\n",
      "Learning Rate: 0.01\n",
      "Minibatch Size: 4\n",
      "---------------\n",
      "---------------\n",
      "| Loss Function | : cross_entropy\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "---------------\n",
      "| Trainable Parameters | \n",
      "---------------\n",
      "{'W_input_hidden_layer': array([[-0.66157275, -0.40900101],\n",
      "       [-0.63631169, -0.99798354]]), 'hidden': array([ 0.59309058, -0.02415929]), 'W_hidden_output_layer': array([[0.30716018],\n",
      "       [0.79441294]]), 'output': array([-0.04661841])}\n"
     ]
    }
   ],
   "source": [
    "nn = input_layer >> hidden_layer >> output_layer >> loss >> optimizer;\n",
    "nn.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2628.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7417447694348323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nn.train( x_train, y_train );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict( x_test );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
